{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter \n",
    "from collections import deque\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>article_url</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>date</th>\n",
       "      <th>tag_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Top 10 Technology Trends for 2020</td>\n",
       "      <td>https://towardsdatascience.com/top-10-technolo...</td>\n",
       "      <td>3000</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Technology', 'Trends', 'Artificial Intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Top 10 Skills for a Data Scientist</td>\n",
       "      <td>https://towardsdatascience.com/top-10-skills-f...</td>\n",
       "      <td>2200</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Data Science', 'Technology', 'Business', 'Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ML Ops: Machine Learning as an Engineering Dis...</td>\n",
       "      <td>https://towardsdatascience.com/ml-ops-machine-...</td>\n",
       "      <td>1300</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Data Science', 'Machine Learning', 'Data Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Organizing your Python Code</td>\n",
       "      <td>https://medium.com/@k3no/organizing-your-pytho...</td>\n",
       "      <td>1200</td>\n",
       "      <td>13</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Python', 'Programming', 'Data Science', 'Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How to be fancy with OOP in Python</td>\n",
       "      <td>https://towardsdatascience.com/how-to-be-fancy...</td>\n",
       "      <td>928</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Programming', 'Python', 'Data Science', 'Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11730</th>\n",
       "      <td>16044</td>\n",
       "      <td>3 สิ่งน่าสนใจจาก Big data จากโครงการ “ชิมช้อปใช้”</td>\n",
       "      <td>https://medium.com/achieve-space/3-%E0%B8%AA%E...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>['Data Science']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11731</th>\n",
       "      <td>16045</td>\n",
       "      <td>Top Master Data Science Institute in Delhi — C...</td>\n",
       "      <td>https://medium.com/@sunnynsa2019/top-master-da...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>['Master Data Science', 'Data Science']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11732</th>\n",
       "      <td>16046</td>\n",
       "      <td>Data Science and Untapped Possibilities, How M...</td>\n",
       "      <td>https://medium.com/@MaxEd_Blog/data-science-an...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>['Big Data', 'Data Science', 'Data Analytics',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11733</th>\n",
       "      <td>16047</td>\n",
       "      <td>Data Scientist เก่งคิด เก่งพูด นักวิทยาศาสตร์ข...</td>\n",
       "      <td>https://medium.com/achieve-space/data-scientis...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>['Persuasive', 'Presentations', 'Data Science']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11734</th>\n",
       "      <td>16048</td>\n",
       "      <td>Python程序设计9 类编程和内存</td>\n",
       "      <td>https://medium.com/adamedelwiess/python%E7%A8%...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>['About', 'Mathematics', 'Computer Science', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11735 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                              title  \\\n",
       "0          0                  Top 10 Technology Trends for 2020   \n",
       "1          1                 Top 10 Skills for a Data Scientist   \n",
       "2          2  ML Ops: Machine Learning as an Engineering Dis...   \n",
       "3          3                        Organizing your Python Code   \n",
       "4          4                 How to be fancy with OOP in Python   \n",
       "...      ...                                                ...   \n",
       "11730  16044  3 สิ่งน่าสนใจจาก Big data จากโครงการ “ชิมช้อปใช้”   \n",
       "11731  16045  Top Master Data Science Institute in Delhi — C...   \n",
       "11732  16046  Data Science and Untapped Possibilities, How M...   \n",
       "11733  16047  Data Scientist เก่งคิด เก่งพูด นักวิทยาศาสตร์ข...   \n",
       "11734  16048                                 Python程序设计9 类编程和内存   \n",
       "\n",
       "                                             article_url  claps  reading_time  \\\n",
       "0      https://towardsdatascience.com/top-10-technolo...   3000            10   \n",
       "1      https://towardsdatascience.com/top-10-skills-f...   2200             9   \n",
       "2      https://towardsdatascience.com/ml-ops-machine-...   1300            10   \n",
       "3      https://medium.com/@k3no/organizing-your-pytho...   1200            13   \n",
       "4      https://towardsdatascience.com/how-to-be-fancy...    928             3   \n",
       "...                                                  ...    ...           ...   \n",
       "11730  https://medium.com/achieve-space/3-%E0%B8%AA%E...      0             2   \n",
       "11731  https://medium.com/@sunnynsa2019/top-master-da...      1             3   \n",
       "11732  https://medium.com/@MaxEd_Blog/data-science-an...      0             3   \n",
       "11733  https://medium.com/achieve-space/data-scientis...      0             2   \n",
       "11734  https://medium.com/adamedelwiess/python%E7%A8%...      0            15   \n",
       "\n",
       "             date                                           tag_list  \n",
       "0      2020-01-03  ['Technology', 'Trends', 'Artificial Intellige...  \n",
       "1      2020-01-03  ['Data Science', 'Technology', 'Business', 'Ma...  \n",
       "2      2020-01-03  ['Data Science', 'Machine Learning', 'Data Eng...  \n",
       "3      2020-01-03  ['Python', 'Programming', 'Data Science', 'Cod...  \n",
       "4      2020-01-03  ['Programming', 'Python', 'Data Science', 'Cod...  \n",
       "...           ...                                                ...  \n",
       "11730  2020-08-19                                   ['Data Science']  \n",
       "11731  2020-08-19            ['Master Data Science', 'Data Science']  \n",
       "11732  2020-08-19  ['Big Data', 'Data Science', 'Data Analytics',...  \n",
       "11733  2020-08-19    ['Persuasive', 'Presentations', 'Data Science']  \n",
       "11734  2020-08-19  ['About', 'Mathematics', 'Computer Science', '...  \n",
       "\n",
       "[11735 rows x 7 columns]"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_articles = pd.read_csv('medium_articles.csv')\n",
    "medium_articles.head()\n",
    "\n",
    "def clean(lst):\n",
    "    \"\"\"Fixes error in my tag_list code (for more info read the README.md file)\"\"\"\n",
    "    lst = ast.literal_eval(lst) # convert string list into actual list\n",
    "    if '★' in lst:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "medium_articles['temp'] = medium_articles['tag_list'].apply(clean)\n",
    "medium_articles = medium_articles.loc[medium_articles.temp].reset_index(inplace=False)\n",
    "medium_articles = medium_articles.drop(['temp'], axis = 1)\n",
    "copy = medium_articles.copy()\n",
    "medium_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Technology': 453,\n",
       " 'Trends': 23,\n",
       " 'Artificial Intelligence': 1714,\n",
       " 'Data Science': 11735,\n",
       " 'Future': 21,\n",
       " 'Business': 134,\n",
       " 'Machine Learning': 4040,\n",
       " 'Data': 1077,\n",
       " 'Data Engineering': 172,\n",
       " 'DevOps': 39,\n",
       " 'Towards Data Science': 173,\n",
       " 'Python': 1748,\n",
       " 'Programming': 421,\n",
       " 'Coding': 82,\n",
       " 'Software Development': 117,\n",
       " 'Statistics': 540,\n",
       " 'Analytics': 571,\n",
       " 'Experiment': 10,\n",
       " 'Gojek': 2,\n",
       " 'GIS': 12,\n",
       " 'Geography': 8,\n",
       " 'Data Analysis': 630,\n",
       " 'Project Management': 20,\n",
       " 'Construction': 2,\n",
       " 'Project Controls': 1,\n",
       " 'Megaprojects': 1,\n",
       " 'Kaggle': 90,\n",
       " 'Hackathons': 13,\n",
       " 'Ensemble': 3,\n",
       " 'Performance Marketing': 1,\n",
       " 'Martech': 2,\n",
       " 'Media Mix Modeling': 1,\n",
       " 'NFL': 9,\n",
       " 'Super Bowl': 4,\n",
       " 'Predictions': 32,\n",
       " 'NLP': 343,\n",
       " 'Product Science': 1,\n",
       " 'Autocorrelation': 2,\n",
       " 'Partial Autocorrelation': 1,\n",
       " 'Covariance Matrix': 1,\n",
       " 'Time Series Analysis': 51,\n",
       " 'Web Scraping': 105,\n",
       " 'R Shiny': 4,\n",
       " 'Rstudio': 37,\n",
       " 'Data Enthusiast': 3,\n",
       " 'K Means Clustering': 25,\n",
       " 'Cluster Analysis': 5,\n",
       " 'JavaScript': 38,\n",
       " 'Nuances Of Programming': 40,\n",
       " 'Neural Networks': 160,\n",
       " 'Deep Learning': 812,\n",
       " 'Cheminformatics': 2,\n",
       " 'Diversity': 8,\n",
       " 'Hiring': 13,\n",
       " 'Management': 28,\n",
       " 'TensorFlow': 71,\n",
       " 'Inteligencia Artificial': 31,\n",
       " 'Visão Computacional': 1,\n",
       " 'Object Detection': 26,\n",
       " 'Movies': 25,\n",
       " 'Media': 18,\n",
       " 'Power Bi': 37,\n",
       " 'Structured Thinking': 1,\n",
       " 'Hypothesis Testing': 25,\n",
       " 'Getting Started': 5,\n",
       " 'Docker': 31,\n",
       " 'Jetson Nano': 1,\n",
       " 'Health': 78,\n",
       " 'Data Visualization': 1184,\n",
       " 'Money': 9,\n",
       " 'Recommender Systems': 23,\n",
       " 'Recommender Engine': 1,\n",
       " 'Feature Engineering': 54,\n",
       " 'Count Vectorizer': 1,\n",
       " 'Bitcoin': 26,\n",
       " 'Bitso': 1,\n",
       " 'Numpy': 50,\n",
       " 'Pandas': 224,\n",
       " 'Sketch': 1,\n",
       " 'Data Scientist': 206,\n",
       " 'Search': 7,\n",
       " 'Ab Testing': 16,\n",
       " 'Tutorial': 75,\n",
       " 'Visualization': 113,\n",
       " 'Insurance': 4,\n",
       " 'AI': 570,\n",
       " 'Disruption': 1,\n",
       " 'Movielens': 1,\n",
       " 'Udacity Nanodegree': 62,\n",
       " 'Dsnd': 2,\n",
       " 'Big Data': 464,\n",
       " 'Apache Spark': 26,\n",
       " 'Aegis Infoways': 1,\n",
       " 'Python3': 93,\n",
       " 'Python Programming': 115,\n",
       " 'R': 138,\n",
       " 'Blockchain': 57,\n",
       " 'Medium Español': 1,\n",
       " 'News': 36,\n",
       " 'Data Journalism': 18,\n",
       " 'Charts': 17,\n",
       " 'Maps': 23,\n",
       " 'Traits': 1,\n",
       " 'Airflow': 12,\n",
       " 'Dağ': 1,\n",
       " 'Startup': 79,\n",
       " 'Creativity': 6,\n",
       " 'Vidéo': 1,\n",
       " 'Classification': 88,\n",
       " 'Excel': 22,\n",
       " 'Intern': 6,\n",
       " 'Review': 10,\n",
       " 'Lecture Notes': 1,\n",
       " 'Computer Vision': 125,\n",
       " 'Botany': 1,\n",
       " 'Predictive Analytics': 55,\n",
       " 'Hiring Strategy': 1,\n",
       " 'Engineer': 1,\n",
       " 'Healthcare': 75,\n",
       " 'Zorg': 1,\n",
       " 'Innovation': 36,\n",
       " 'Generative Adversarial': 7,\n",
       " 'Generative Model': 4,\n",
       " 'Politics': 60,\n",
       " 'Democrats': 3,\n",
       " 'Data Science Training': 139,\n",
       " 'Python For Data Science': 5,\n",
       " 'Gaussian Mixture Model': 2,\n",
       " 'Anaconda': 22,\n",
       " 'Database': 109,\n",
       " 'Recommendation System': 46,\n",
       " 'Pandas Dataframe': 34,\n",
       " 'Xlwings': 1,\n",
       " 'Values': 3,\n",
       " 'Sociology': 5,\n",
       " 'Graduate School': 10,\n",
       " 'New Years Resolutions': 2,\n",
       " 'New Years Reflections': 1,\n",
       " 'Design Process': 2,\n",
       " 'Optimization Algorithms': 4,\n",
       " 'Azerbaijan': 3,\n",
       " 'Business Analytics': 28,\n",
       " 'WNBA': 1,\n",
       " 'Womens Basketball': 1,\n",
       " 'Historical Data': 1,\n",
       " 'Science': 94,\n",
       " 'Synthetic Biology': 1,\n",
       " 'Modelling And Simulation': 5,\n",
       " 'Genetic Engineering': 1,\n",
       " 'Taylor Swift': 3,\n",
       " 'Text Analysis': 7,\n",
       " 'Nltk': 8,\n",
       " 'Topic Modeling': 17,\n",
       " 'University': 7,\n",
       " 'Waterloo': 1,\n",
       " 'Big Data Analytics': 79,\n",
       " 'Statistical Analysis': 35,\n",
       " 'Data Analytics': 301,\n",
       " 'Enterpreneurship': 1,\n",
       " 'Google Colab': 15,\n",
       " 'Dataset': 22,\n",
       " 'Image Segmentation': 5,\n",
       " 'Marijuana': 2,\n",
       " 'Cannabis': 4,\n",
       " 'Cyrptocurrency': 2,\n",
       " 'Face Recognition': 9,\n",
       " 'Opencv': 18,\n",
       " 'Network': 6,\n",
       " '2020 Presidential Race': 4,\n",
       " 'Careers': 89,\n",
       " 'Colab': 8,\n",
       " 'Jupyter Notebook': 103,\n",
       " 'Wordpress Plugins': 1,\n",
       " 'Web Development': 41,\n",
       " 'Google': 38,\n",
       " 'Immigration': 3,\n",
       " 'Visa': 1,\n",
       " 'UK': 4,\n",
       " 'Jobs': 30,\n",
       " 'Image Processing': 36,\n",
       " 'Data Science Use Cases': 1,\n",
       " 'Insurance Use Cases': 1,\n",
       " 'Life Insurance': 1,\n",
       " 'D3js': 5,\n",
       " 'AWS': 84,\n",
       " 'Terraform': 3,\n",
       " 'Snowflake': 5,\n",
       " 'Regression': 67,\n",
       " 'Cluster': 3,\n",
       " 'Clustering': 69,\n",
       " 'Hierarchical Clustering': 5,\n",
       " 'Machine Intelligence': 20,\n",
       " 'Ethics In Tech': 2,\n",
       " 'Language': 3,\n",
       " 'Vernacular': 1,\n",
       " 'Content': 8,\n",
       " 'Product Management': 46,\n",
       " 'Digitalization': 1,\n",
       " 'Cancer': 7,\n",
       " 'Image Dataset': 1,\n",
       " 'Medicine': 19,\n",
       " 'Naive Bayes Classifier': 7,\n",
       " 'Pyhton': 2,\n",
       " 'Information Theory': 4,\n",
       " 'Lstm': 13,\n",
       " 'Experimentation': 10,\n",
       " 'Data Analyst': 31,\n",
       " 'Business Strategy': 40,\n",
       " 'Customer Segmentation': 18,\n",
       " 'Target Market': 1,\n",
       " 'Linear Regression': 103,\n",
       " 'Regression Analysis': 23,\n",
       " 'Udacity': 95,\n",
       " 'Central Tendency': 4,\n",
       " 'Agile Machine Learning': 1,\n",
       " 'Ensemble Learning': 17,\n",
       " 'Sarimax': 1,\n",
       " 'Seasonal Decomposition': 1,\n",
       " 'Azerbaycan': 1,\n",
       " 'Decision Tree': 41,\n",
       " 'Dental': 1,\n",
       " 'Snowflake Computing': 3,\n",
       " 'Distance': 2,\n",
       " 'Naturallanguageprocessing': 114,\n",
       " 'Workplace': 2,\n",
       " 'Growth': 16,\n",
       " 'Image Recognition': 10,\n",
       " 'Cybersecurity': 32,\n",
       " 'Internships': 25,\n",
       " 'Agile': 18,\n",
       " 'Facedetection': 3,\n",
       " 'Interactive Visualization': 1,\n",
       " 'Patterns': 2,\n",
       " 'Triangle': 1,\n",
       " 'Okcupid': 1,\n",
       " 'Online Dating': 1,\n",
       " 'Text Mining': 23,\n",
       " 'Algorithms': 113,\n",
       " 'Akshaj Wields Pytorch': 7,\n",
       " 'Cloud': 20,\n",
       " 'Boule De Cristal': 1,\n",
       " 'Culture': 10,\n",
       " 'Leadership': 52,\n",
       " 'Leadership Development': 5,\n",
       " 'Probability Distributions': 4,\n",
       " 'Dataanalys': 8,\n",
       " 'Women In Data Science': 12,\n",
       " 'Data Science Job': 10,\n",
       " 'Pickle': 1,\n",
       " 'Serialization': 1,\n",
       " 'Joblib': 3,\n",
       " 'Clip': 1,\n",
       " 'Data For Good': 8,\n",
       " 'Ola': 1,\n",
       " 'Hive': 1,\n",
       " 'Sql': 98,\n",
       " 'Sample': 2,\n",
       " 'Airbnb': 131,\n",
       " 'Silicon Valley': 3,\n",
       " 'Critical Thinking': 3,\n",
       " 'Education': 118,\n",
       " 'Correlation Vs Causation': 3,\n",
       " 'Team Management': 2,\n",
       " 'Learning': 96,\n",
       " 'Hadoop': 23,\n",
       " 'Framework': 5,\n",
       " 'Spark': 59,\n",
       " 'Citi Bike': 1,\n",
       " 'Opencv Python': 11,\n",
       " 'Azərbaycan': 1,\n",
       " 'Certification': 15,\n",
       " 'Analytics Vidhya': 10,\n",
       " 'Logistic Regression': 55,\n",
       " 'Datascience Training': 12,\n",
       " 'Dating': 130,\n",
       " 'Life Lessons': 10,\n",
       " 'Netflix': 16,\n",
       " 'Streaming': 9,\n",
       " 'Bees': 1,\n",
       " 'Simulation': 12,\n",
       " 'Monte Carlo': 4,\n",
       " 'Card Game': 1,\n",
       " 'Tech': 56,\n",
       " 'Phoenix': 2,\n",
       " 'The Simpsons': 1,\n",
       " 'Iteration': 2,\n",
       " 'Data Cleaning': 53,\n",
       " 'Friends': 2,\n",
       " 'Podcast': 24,\n",
       " 'Supervised Learning': 47,\n",
       " 'Data Mining': 97,\n",
       " 'Lattice': 1,\n",
       " 'Data Manipulation': 7,\n",
       " 'Explainable Ai': 16,\n",
       " 'Ethical Ai': 2,\n",
       " 'Merci': 1,\n",
       " 'Internship Experience': 4,\n",
       " 'Paris': 2,\n",
       " 'Costa Rica': 3,\n",
       " 'Cornell University': 2,\n",
       " 'Food': 19,\n",
       " 'Sqlite3': 2,\n",
       " 'Interview Preparation': 5,\n",
       " 'Sales': 41,\n",
       " 'Database Administration': 1,\n",
       " 'Kubernetes': 16,\n",
       " 'Orchestration': 3,\n",
       " 'Data Processing': 12,\n",
       " 'Pca': 6,\n",
       " 'Dimensionality Reduction': 17,\n",
       " 'Instacart': 1,\n",
       " 'Kaggle Competition': 17,\n",
       " 'Monitoring': 2,\n",
       " 'Dataops': 14,\n",
       " 'Mathematics': 119,\n",
       " 'Physics': 5,\n",
       " 'K Means': 27,\n",
       " 'Data Visualisation': 20,\n",
       " 'Dashboard': 32,\n",
       " 'Interactive': 3,\n",
       " 'Feature Selection': 10,\n",
       " 'Natural Language Process': 9,\n",
       " 'Spacy': 4,\n",
       " 'Fintech': 23,\n",
       " 'Trading': 21,\n",
       " 'Advanced Analytics': 9,\n",
       " 'Amazon Sagemaker': 4,\n",
       " 'Walmart': 1,\n",
       " 'Pharmacy': 1,\n",
       " 'Sentiment Analysis': 45,\n",
       " 'Interview': 66,\n",
       " 'Enem': 3,\n",
       " 'Meritocracia': 1,\n",
       " 'Ciencia De Dados': 66,\n",
       " 'Brasil': 13,\n",
       " 'Scientific Method': 2,\n",
       " 'Berkeley': 3,\n",
       " 'Storytelling': 41,\n",
       " 'Xcelerator': 2,\n",
       " 'Boston': 22,\n",
       " 'Bokeh': 6,\n",
       " 'Csv': 9,\n",
       " 'Import': 1,\n",
       " 'Gmail': 1,\n",
       " 'Contact': 1,\n",
       " 'Missing Values': 5,\n",
       " 'Missing Data': 14,\n",
       " 'Versioning': 1,\n",
       " 'Version Control System': 1,\n",
       " 'Metrics': 16,\n",
       " 'Precision': 7,\n",
       " 'Recall': 5,\n",
       " 'Digital Transformation': 37,\n",
       " 'Decision Science': 2,\n",
       " 'Mlops': 25,\n",
       " 'Country': 2,\n",
       " 'Exploratory Data Analysis': 91,\n",
       " 'Aws Sagemaker': 2,\n",
       " 'Strategy': 23,\n",
       " 'Inside Ai': 7,\n",
       " 'Time Series Forecasting': 38,\n",
       " 'Delaware': 1,\n",
       " 'Philadelphia': 1,\n",
       " 'Egypt': 1,\n",
       " 'Algeria': 1,\n",
       " 'Sudan': 1,\n",
       " 'World Bank': 1,\n",
       " 'Pipeline': 9,\n",
       " 'Reusable Component': 1,\n",
       " 'Real Estate': 16,\n",
       " 'Walter Offer': 1,\n",
       " 'Bidding Strategies': 2,\n",
       " 'Buying A Home': 1,\n",
       " 'Bioinformatics': 12,\n",
       " 'Engineering': 63,\n",
       " 'IoT': 29,\n",
       " 'Redes Neurais': 2,\n",
       " 'Flask': 25,\n",
       " 'Xgboost': 19,\n",
       " 'Dreams': 2,\n",
       " 'Affective Computing': 1,\n",
       " 'Univem': 1,\n",
       " '2020': 10,\n",
       " 'Cientista De Dados': 6,\n",
       " 'Marketing': 70,\n",
       " 'Anthropology': 2,\n",
       " 'Unesco': 1,\n",
       " 'Digital Anthropology': 1,\n",
       " 'Cultural Anthropology': 1,\n",
       " 'Data Quality': 10,\n",
       " 'Data Quality Management': 1,\n",
       " 'Data Integration': 5,\n",
       " 'Data Leakage Prevention': 1,\n",
       " 'Salary': 9,\n",
       " 'Salary Survey': 1,\n",
       " 'Work Engagement': 1,\n",
       " 'Productivity': 28,\n",
       " 'Engagement': 2,\n",
       " 'Atrae': 1,\n",
       " 'Cryptogames': 1,\n",
       " 'Motivation Data Science': 1,\n",
       " 'Why Ml': 1,\n",
       " 'Why Data Science': 2,\n",
       " 'Cloud Computing': 55,\n",
       " 'Data Center': 2,\n",
       " 'Directors': 2,\n",
       " 'Algebra': 1,\n",
       " 'Quality Assurance': 4,\n",
       " 'Software Testing': 1,\n",
       " 'Automation': 36,\n",
       " 'Data Science Life Cycle': 3,\n",
       " 'Data Science Projects': 6,\n",
       " 'Machine Learning Projects': 2,\n",
       " 'Soccer Analytics': 5,\n",
       " 'Calcio': 2,\n",
       " 'Soccer': 12,\n",
       " 'Feedback Loop': 1,\n",
       " 'Active Learning': 2,\n",
       " 'Reinforcement Learning': 40,\n",
       " 'Graphical Data': 1,\n",
       " 'Statistical Data': 1,\n",
       " 'Analysis Softwares': 1,\n",
       " 'ML': 8,\n",
       " 'Scikit Learn': 33,\n",
       " 'Crossvalidation': 13,\n",
       " 'Matplotlib': 42,\n",
       " 'Cryptocurrency': 40,\n",
       " 'Hedge Funds': 5,\n",
       " 'Erasure': 1,\n",
       " 'Java': 20,\n",
       " 'Intellij': 1,\n",
       " 'Mapreduce': 3,\n",
       " 'Fraud Detection': 8,\n",
       " 'Business Intelligence': 128,\n",
       " 'Career Change': 30,\n",
       " 'Testing': 17,\n",
       " 'Rankings': 2,\n",
       " 'Fraud': 6,\n",
       " 'Electric Vehicles': 5,\n",
       " 'Charging Station': 1,\n",
       " 'Fleet Management': 5,\n",
       " 'Mobility': 14,\n",
       " 'Dengue': 4,\n",
       " 'Weather': 8,\n",
       " 'Beginner': 54,\n",
       " 'Writing': 8,\n",
       " 'Career Advice': 50,\n",
       " 'Soft Skills': 4,\n",
       " 'Ibm Spss Modeller': 2,\n",
       " 'Knime': 6,\n",
       " 'Rapidminer': 3,\n",
       " 'Data Mining Tool': 1,\n",
       " 'Cloud9': 1,\n",
       " 'AWS Lambda': 5,\n",
       " 'Code Review': 2,\n",
       " 'Knowledge Sharing': 2,\n",
       " 'Machine Translation': 3,\n",
       " 'Dengue Fever': 1,\n",
       " 'Spotify': 19,\n",
       " 'Coachella': 1,\n",
       " 'Correlation': 15,\n",
       " 'Descriptive Statistics': 12,\n",
       " 'Descriptive': 1,\n",
       " 'Dengue Prevention': 1,\n",
       " 'Climate': 3,\n",
       " 'Keyword Research': 2,\n",
       " 'Singapore': 5,\n",
       " 'Data Driven': 21,\n",
       " 'Support Vector Machine': 12,\n",
       " 'Electric Car': 4,\n",
       " 'Data Science Tutorial': 1,\n",
       " 'Supermarket': 1,\n",
       " 'Shopping': 3,\n",
       " 'Customer Satisfaction': 2,\n",
       " 'Customer Churn': 5,\n",
       " 'Pyspark': 19,\n",
       " 'Altair': 3,\n",
       " 'Data Wrangling': 14,\n",
       " 'Common Mistakes': 1,\n",
       " 'Random Forest': 29,\n",
       " 'Lambda School': 9,\n",
       " 'Dispersion': 2,\n",
       " 'Startup Lessons': 5,\n",
       " 'Missing Variable': 1,\n",
       " 'Security': 21,\n",
       " 'Vertica': 1,\n",
       " 'Artificial Neural Network': 12,\n",
       " 'Timeseries': 13,\n",
       " 'Anomaly Detection': 16,\n",
       " 'Dataframes': 11,\n",
       " 'Flattening': 1,\n",
       " 'Hyperparameter Tuning': 7,\n",
       " 'Relationships': 7,\n",
       " 'Deploy': 4,\n",
       " 'Course': 25,\n",
       " 'Skills': 13,\n",
       " 'Nlp Certification': 1,\n",
       " 'Nlp Training': 3,\n",
       " 'Traffic': 4,\n",
       " 'Training': 21,\n",
       " 'Pune': 2,\n",
       " 'Techdata Solutions': 1,\n",
       " 'Sales Forecasting': 5,\n",
       " 'Forecasting': 34,\n",
       " 'Quantitative': 2,\n",
       " 'Qualitative': 1,\n",
       " 'Ceph': 1,\n",
       " 'Kafka': 4,\n",
       " 'Knative': 1,\n",
       " 'Data Pipeline': 17,\n",
       " 'Social Media': 27,\n",
       " 'Iran': 2,\n",
       " 'Journalism': 19,\n",
       " 'Resume': 8,\n",
       " 'Harvard': 3,\n",
       " '日本語': 3,\n",
       " 'UX': 18,\n",
       " 'Measurement': 2,\n",
       " 'Eye Tracking': 1,\n",
       " 'Microsoft': 39,\n",
       " 'Azure': 30,\n",
       " 'Decision Making': 45,\n",
       " 'Optimization': 40,\n",
       " 'Consulting': 20,\n",
       " 'Computer Science': 117,\n",
       " 'Pymc3': 2,\n",
       " 'Survival Analysis': 6,\n",
       " 'Probabilistic Programming': 3,\n",
       " 'Communication': 7,\n",
       " 'Communication Skills': 1,\n",
       " 'Curse Of Knowledge': 1,\n",
       " 'Python 3 Tutorial': 1,\n",
       " 'Market Basket Analysis': 10,\n",
       " 'Retail': 26,\n",
       " 'Dask': 4,\n",
       " 'Nyc Parking Ticket': 1,\n",
       " 'Geoffrey Hinton': 1,\n",
       " 'Running': 2,\n",
       " 'Gaming': 10,\n",
       " 'Geoai': 1,\n",
       " 'Machinelearning': 6,\n",
       " 'Geospatial': 30,\n",
       " 'Best Of': 1,\n",
       " 'Articles': 1,\n",
       " 'Energy Efficiency': 7,\n",
       " 'Commercial Real Estate': 1,\n",
       " 'Sustainability': 8,\n",
       " 'Color Detection': 1,\n",
       " 'Flowers': 1,\n",
       " 'Sklearn': 18,\n",
       " 'Convolution Neural Net': 9,\n",
       " 'Professional Development': 1,\n",
       " 'Africa': 20,\n",
       " 'Forex': 2,\n",
       " 'Bitgrit': 6,\n",
       " 'Iit': 2,\n",
       " 'Workflow': 15,\n",
       " 'Machine Learning Tools': 10,\n",
       " 'Sports': 36,\n",
       " 'Baseball': 10,\n",
       " 'Astros': 2,\n",
       " 'Infrastructure': 9,\n",
       " 'Bentley Systems': 1,\n",
       " 'Microstation': 1,\n",
       " 'Excel Integration': 1,\n",
       " 'Data Labeling': 4,\n",
       " 'Sabermetrics': 1,\n",
       " 'Statcast': 2,\n",
       " 'Surveys': 10,\n",
       " 'Study': 5,\n",
       " 'Hotel Reviews': 1,\n",
       " 'Tripadvisor': 1,\n",
       " 'Children': 3,\n",
       " 'Date Night': 1,\n",
       " 'Medical Statistics': 1,\n",
       " 'Medical Book': 1,\n",
       " 'Free Medical Books': 1,\n",
       " 'Medical Book Pdf': 1,\n",
       " 'Dataworkspaces': 1,\n",
       " 'No Code': 7,\n",
       " 'Problem Solving': 11,\n",
       " 'Data Model': 3,\n",
       " 'Football': 28,\n",
       " 'Data Science Recaps': 1,\n",
       " 'Business Transformation': 2,\n",
       " 'Business Improvement': 1,\n",
       " 'Organizational Change': 1,\n",
       " 'MySQL': 10,\n",
       " 'Xampp': 2,\n",
       " 'Digital Marketing': 28,\n",
       " 'Highest Paying': 1,\n",
       " 'Market Research Reports': 3,\n",
       " 'Métricas': 1,\n",
       " 'Calibration Of': 1,\n",
       " 'Welding Machines': 1,\n",
       " 'Astrology': 241,\n",
       " 'Advertising': 134,\n",
       " 'Art': 201,\n",
       " 'Travel': 103,\n",
       " 'Real Time Analytics': 4,\n",
       " 'Logivan': 2,\n",
       " 'Bayesian': 2,\n",
       " 'Educational Data Mining': 1,\n",
       " 'Evasão': 1,\n",
       " 'Ensino Superior': 1,\n",
       " 'Educação': 2,\n",
       " 'Games': 3,\n",
       " 'Pokemon': 4,\n",
       " 'Hate Speech': 1,\n",
       " 'Music': 30,\n",
       " 'Scraping': 10,\n",
       " 'Andrew Ng': 2,\n",
       " 'Black Box': 2,\n",
       " '資料科學': 4,\n",
       " '人工智慧': 2,\n",
       " 'Causality': 10,\n",
       " 'Simpsons Paradox': 2,\n",
       " 'Data Rescue': 1,\n",
       " 'Boxing': 1,\n",
       " 'Finance': 70,\n",
       " 'Investing': 28,\n",
       " 'Financial Services': 3,\n",
       " 'Performance': 9,\n",
       " 'Linux': 18,\n",
       " 'Nan': 2,\n",
       " 'Climate Change': 22,\n",
       " 'Fema': 1,\n",
       " 'Python Training Course': 2,\n",
       " 'Career': 6,\n",
       " 'Predictive Modeling': 28,\n",
       " 'Career Development': 13,\n",
       " 'Selling': 1,\n",
       " 'Data Preprocessing': 33,\n",
       " 'Infographics': 12,\n",
       " 'Subscription': 4,\n",
       " 'Lympo': 1,\n",
       " 'SaaS': 12,\n",
       " 'Growth Hacking': 10,\n",
       " 'Oscars': 1,\n",
       " 'Data Analytics Tools': 8,\n",
       " 'Housing': 9,\n",
       " 'Plotly': 25,\n",
       " 'Fire': 1,\n",
       " 'Dumpster Fire': 1,\n",
       " 'Introvert': 2,\n",
       " 'Extrovert': 1,\n",
       " 'Imbalanced Data': 8,\n",
       " 'Economic Development': 1,\n",
       " 'Political Science': 5,\n",
       " 'Seattle': 27,\n",
       " 'Christmas': 1,\n",
       " 'Google Analytics': 8,\n",
       " 'Data Commons': 1,\n",
       " 'Version Control': 4,\n",
       " 'Nutrition': 1,\n",
       " 'Entrepreneurship': 21,\n",
       " 'Seaborn': 24,\n",
       " 'Applications Development': 1,\n",
       " 'Stochastic Model': 1,\n",
       " 'Non Finite Variance': 1,\n",
       " 'Black Scholes Equation': 1,\n",
       " 'Cauchy Distribution': 1,\n",
       " 'Projects': 30,\n",
       " '311': 2,\n",
       " 'New York': 7,\n",
       " 'Noise': 1,\n",
       " 'Competition': 11,\n",
       " 'Tire Exhibition': 1,\n",
       " 'Pytorch': 63,\n",
       " 'Transfer Learning': 9,\n",
       " 'Governance': 5,\n",
       " 'Cricket': 9,\n",
       " 'Sports An': 1,\n",
       " 'Shiny': 4,\n",
       " 'Compression': 1,\n",
       " 'GIF': 1,\n",
       " 'Structured Query Language': 1,\n",
       " 'Regression Testing': 2,\n",
       " 'Naturallanguagegeneration': 1,\n",
       " 'Unsupervised Learning': 53,\n",
       " 'Clustering Algorithm': 8,\n",
       " 'Women In Tech': 53,\n",
       " 'ประสบการณ์': 2,\n",
       " 'Git': 11,\n",
       " 'Dvc': 2,\n",
       " 'Nuclear': 1,\n",
       " 'Nuclear Energy': 1,\n",
       " 'Nuclear Medicine': 1,\n",
       " 'Puerto Rico': 2,\n",
       " 'Humanitarian': 1,\n",
       " 'Data Driven Decisions': 12,\n",
       " 'Software Industry': 1,\n",
       " 'General Assembly': 15,\n",
       " 'Kathirvel Kumararaja': 1,\n",
       " 'Glassdoor': 1,\n",
       " 'Beautifulsoup': 25,\n",
       " 'Company Review': 1,\n",
       " 'Data Science Courses': 72,\n",
       " 'Polish': 2,\n",
       " 'New Year': 1,\n",
       " 'Hypothesis': 4,\n",
       " 'Anova': 5,\n",
       " 'Corrections': 2,\n",
       " 'Tests Of Normality': 1,\n",
       " 'Command Line': 4,\n",
       " 'Debugging': 4,\n",
       " 'Mumbai': 1,\n",
       " 'Techdatasolution': 1,\n",
       " 'Analyst': 5,\n",
       " 'Software Engineering': 52,\n",
       " 'All': 6,\n",
       " 'Eda': 41,\n",
       " 'Tableau': 67,\n",
       " 'Mba': 2,\n",
       " 'Industry Insights': 2,\n",
       " 'Telecom': 4,\n",
       " 'Churn': 13,\n",
       " 'Data Governance': 9,\n",
       " 'Jiu Jitsu': 1,\n",
       " 'Price Optimization': 1,\n",
       " 'Demand Forecasting': 2,\n",
       " 'Rmysql': 1,\n",
       " 'Zomato': 4,\n",
       " 'Arima': 9,\n",
       " 'Random Wa': 1,\n",
       " 'Exchange Rate': 1,\n",
       " 'Éducation': 1,\n",
       " 'Female Founders': 1,\n",
       " 'Json': 4,\n",
       " 'Pandas Database': 1,\n",
       " 'Data Preparation': 15,\n",
       " 'Stock Market': 28,\n",
       " 'Stocks': 6,\n",
       " 'Hardware': 3,\n",
       " 'History': 11,\n",
       " 'Powerlifting': 1,\n",
       " 'Weightlifting': 1,\n",
       " 'Fitness': 4,\n",
       " 'R Programming': 45,\n",
       " 'Phpmyadmin': 1,\n",
       " 'Online Education': 5,\n",
       " 'Ggplot2': 8,\n",
       " 'Histograms': 5,\n",
       " 'Scatter Plots': 3,\n",
       " 'Machine Learning Ai': 21,\n",
       " 'Data Science Careers': 10,\n",
       " 'Metis': 2,\n",
       " 'Finance And Banking': 3,\n",
       " 'Deployment': 20,\n",
       " 'College Football': 2,\n",
       " 'LSU Tigers': 1,\n",
       " 'Journal': 1,\n",
       " 'Web': 4,\n",
       " 'Hire Web Developer': 1,\n",
       " 'Classification Models': 7,\n",
       " 'Mobile Gaming': 1,\n",
       " 'Wildlife Studios': 5,\n",
       " 'Microbiome': 1,\n",
       " 'Metagenomics': 1,\n",
       " 'Power Analysis': 1,\n",
       " 'Jupyter': 14,\n",
       " 'Government': 11,\n",
       " 'Govtech': 2,\n",
       " 'Feature Transformation': 1,\n",
       " '2019 Year In Review': 1,\n",
       " 'Biostatistics': 8,\n",
       " 'Integrity': 1,\n",
       " 'Interview Tips': 5,\n",
       " 'Barcelona': 3,\n",
       " 'Technolog': 2,\n",
       " 'Hindi': 4,\n",
       " 'Aritificial Intelligence': 7,\n",
       " 'Venture Capital': 18,\n",
       " 'Donald Trump': 2,\n",
       " 'Pulsar': 1,\n",
       " 'Apache Pulsar': 1,\n",
       " 'Messaging': 1,\n",
       " 'Instagram': 4,\n",
       " 'Transportation': 11,\n",
       " 'Mapping': 9,\n",
       " 'Marketing Strategies': 13,\n",
       " 'Research': 54,\n",
       " 'Estatistica': 14,\n",
       " 'Wimlds': 4,\n",
       " 'Chinese': 3,\n",
       " 'Chrome Extension': 1,\n",
       " 'Predict': 1,\n",
       " 'Tdd': 1,\n",
       " 'Sainsburys': 1,\n",
       " 'React': 3,\n",
       " 'Serverless': 9,\n",
       " 'Evolution': 1,\n",
       " 'Reflections': 7,\n",
       " 'Coffee': 19,\n",
       " 'Code': 13,\n",
       " 'North Carolina State': 1,\n",
       " 'Data Storytelling': 14,\n",
       " 'Planejamento': 1,\n",
       " 'Análise De Dados': 21,\n",
       " 'Agile Data Science': 1,\n",
       " 'Disney': 2,\n",
       " 'Odsc': 1,\n",
       " 'Conference': 8,\n",
       " 'Recommendations': 13,\n",
       " 'Google Code In': 1,\n",
       " 'Data Science For Business': 1,\n",
       " 'Online Learning': 23,\n",
       " 'Facebook Developer Circle': 1,\n",
       " 'Coimbatore': 1,\n",
       " 'Role Playing Games': 1,\n",
       " 'Neurips': 2,\n",
       " 'New Zealand': 1,\n",
       " 'Analysis': 78,\n",
       " 'Nederlands': 1,\n",
       " 'Lubuntu': 1,\n",
       " 'Virtualbox': 1,\n",
       " 'Heartbeat': 19,\n",
       " 'The Dataframe Series': 1,\n",
       " 'Dataquest': 1,\n",
       " 'Datacamp': 13,\n",
       " 'Learning How To Learn': 1,\n",
       " 'Facebook Prophet': 4,\n",
       " 'Bert': 10,\n",
       " 'Keyword Extraction': 3,\n",
       " 'Lda': 5,\n",
       " 'Tf Idf': 4,\n",
       " 'Ngboost': 2,\n",
       " 'Automl': 22,\n",
       " 'Hyperparameter': 1,\n",
       " 'Fire Detection': 1,\n",
       " 'Visual Anomaly Detection': 1,\n",
       " 'Aiir': 1,\n",
       " 'Time Series': 4,\n",
       " 'Intervention Time Series': 1,\n",
       " 'Interrupted Time Series': 1,\n",
       " 'Econometrics': 11,\n",
       " 'Selenium': 12,\n",
       " 'Mab': 1,\n",
       " 'Sarima': 1,\n",
       " 'Praxis': 2,\n",
       " 'Image': 7,\n",
       " 'Image Resizing': 1,\n",
       " 'Model': 12,\n",
       " 'Crostons Model': 1,\n",
       " 'Time Series Data': 5,\n",
       " 'Architecture': 10,\n",
       " 'Book Review': 5,\n",
       " 'Summary': 1,\n",
       " 'Probability': 51,\n",
       " 'Hypothesis Test': 2,\n",
       " 'Datová Analytika': 1,\n",
       " 'Modeling': 33,\n",
       " 'Garch': 1,\n",
       " 'Arch': 1,\n",
       " 'Timeseries Forecasting': 10,\n",
       " 'Multivariate': 1,\n",
       " 'Markov Chains': 2,\n",
       " 'Markov Models': 2,\n",
       " 'Newsletter': 5,\n",
       " 'Public Health': 30,\n",
       " 'Facerecognitioncamera': 1,\n",
       " 'Dataframe': 3,\n",
       " 'Sorting': 1,\n",
       " 'Economics': 57,\n",
       " 'Time Series Model': 3,\n",
       " 'Forecasting Models': 1,\n",
       " 'Vector Auto Regression': 1,\n",
       " 'Kaggle Api': 1,\n",
       " 'Technical': 3,\n",
       " 'Upskill': 2,\n",
       " 'Codingbootcamp': 13,\n",
       " 'Ocr': 4,\n",
       " 'Analytics Tool': 1,\n",
       " 'Function': 1,\n",
       " 'Hr Artificialintelligence': 1,\n",
       " 'Price Prediction': 4,\n",
       " 'Real World': 1,\n",
       " 'Desmatamento': 1,\n",
       " 'Amazonia': 1,\n",
       " 'Amazônia Legal': 1,\n",
       " 'Strategie Dih': 1,\n",
       " 'P Vs Np': 1,\n",
       " 'Data Pre Processing': 9,\n",
       " 'Music Business': 4,\n",
       " 'Music Industry': 1,\n",
       " 'Collaboration': 13,\n",
       " 'Pittsburgh': 1,\n",
       " 'Bridge': 1,\n",
       " 'Steel': 1,\n",
       " 'It': 6,\n",
       " 'Risk': 3,\n",
       " 'Gestão': 1,\n",
       " 'Empreendedorismo': 1,\n",
       " 'Event Data': 1,\n",
       " 'Feminism': 4,\n",
       " 'Women': 6,\n",
       " 'Future Of Work': 12,\n",
       " 'Open Source': 41,\n",
       " 'Data Imputation': 2,\n",
       " 'Data Science Podcast': 2,\n",
       " 'Numerical Analysis': 2,\n",
       " 'Militares': 1,\n",
       " 'Bolsonaro': 1,\n",
       " 'Análise Exploratória': 3,\n",
       " 'Folha De São Paulo': 1,\n",
       " 'Transformations': 1,\n",
       " 'Open Edx': 1,\n",
       " 'Moodle': 1,\n",
       " 'Digitalocean': 1,\n",
       " 'Future Technology': 9,\n",
       " 'Data Lake': 14,\n",
       " 'Teamwork': 10,\n",
       " 'Charity': 15,\n",
       " 'Advice': 82,\n",
       " 'Targeting': 1,\n",
       " 'March Madness': 3,\n",
       " 'College Basketball': 2,\n",
       " 'Hearthstone': 1,\n",
       " 'Videogames': 8,\n",
       " 'Libraries': 4,\n",
       " 'Tools': 9,\n",
       " '產業觀察': 1,\n",
       " '產業分析': 1,\n",
       " '數據分析': 20,\n",
       " 'Rna Seq': 1,\n",
       " 'Gene Expression': 2,\n",
       " 'Playlist': 2,\n",
       " 'Wealth': 2,\n",
       " 'Success': 6,\n",
       " 'Talent': 3,\n",
       " 'Reqular Expression': 1,\n",
       " 'Privacy': 38,\n",
       " 'Golang': 1,\n",
       " 'Weeknotes': 12,\n",
       " 'Ccpa': 1,\n",
       " 'Data Privacy': 9,\n",
       " 'Hipaa': 1,\n",
       " 'Mitafricans': 1,\n",
       " 'Policy': 13,\n",
       " 'Economy': 10,\n",
       " 'Argentina': 3,\n",
       " 'Simple Linear Regression': 5,\n",
       " 'Datetime': 4,\n",
       " 'Activation Functions': 6,\n",
       " 'Forecast': 3,\n",
       " 'Market': 2,\n",
       " 'Español': 9,\n",
       " 'Autodidacticism': 1,\n",
       " 'Reading': 13,\n",
       " 'Empathy': 1,\n",
       " 'Alternative Data': 8,\n",
       " 'Bias Variance Tradeoff': 10,\n",
       " 'YouTube': 7,\n",
       " 'Process Improvement': 2,\n",
       " 'Data Scientist Career': 7,\n",
       " 'Data Scientist Course': 2,\n",
       " 'Pricing Strategy': 3,\n",
       " 'Business Development': 6,\n",
       " 'Text Processing': 2,\n",
       " 'Stock Trading': 1,\n",
       " 'High Frequency Trading': 1,\n",
       " 'Books': 20,\n",
       " 'Similarity': 3,\n",
       " 'Measure': 1,\n",
       " 'New Blog': 2,\n",
       " 'Autoencoder': 5,\n",
       " 'Enterprise': 2,\n",
       " 'Software': 11,\n",
       " 'Cython': 1,\n",
       " 'C': 2,\n",
       " 'Tensorflow Serving': 1,\n",
       " 'Keras': 31,\n",
       " 'Model Evaluation': 7,\n",
       " 'Collaborative Filtering': 7,\n",
       " 'STEM': 5,\n",
       " 'Busines': 1,\n",
       " 'NBA': 19,\n",
       " 'Systems Thinking': 5,\n",
       " 'Software Ethics': 1,\n",
       " 'Data Protection': 3,\n",
       " 'Sports Analytics': 21,\n",
       " 'Heart Disease': 11,\n",
       " 'Development': 18,\n",
       " 'Retail Technology': 4,\n",
       " 'Product Design': 8,\n",
       " 'Environment': 14,\n",
       " 'Empreinte Carbone': 1,\n",
       " 'Bilan Carbone': 2,\n",
       " 'Écologie': 1,\n",
       " 'Google Cloud Platform': 33,\n",
       " 'Cern': 1,\n",
       " 'Design': 23,\n",
       " 'Deeplearningai': 2,\n",
       " 'Meetup': 4,\n",
       " 'Pricing': 5,\n",
       " 'Learn Data Science': 10,\n",
       " 'Skills Of Data Scientist': 1,\n",
       " 'Job Satisfaction': 3,\n",
       " 'How To Learn': 2,\n",
       " 'Toronto': 6,\n",
       " ...}"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_dict = {} # represents the amount of times a tag has shown up amongst all the articles\n",
    "\n",
    "def tags(lst):\n",
    "    \"\"\"Gets the number of different times a tag was mentioned\"\"\"\n",
    "    lst = ast.literal_eval(lst) # convert string list into actual list\n",
    "    for tag in lst: \n",
    "        if tag in tag_dict.keys():\n",
    "            tag_dict[tag] += 1\n",
    "        else:\n",
    "            tag_dict[tag] = 1\n",
    "            \n",
    "medium_articles['tag_list'].apply(tags)\n",
    "\n",
    "tag_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Machine Learning', 4040),\n",
       " ('Python', 1748),\n",
       " ('Artificial Intelligence', 1714),\n",
       " ('Data Visualization', 1184),\n",
       " ('Data', 1077),\n",
       " ('Deep Learning', 812),\n",
       " ('Covid 19', 637),\n",
       " ('Data Analysis', 630),\n",
       " ('Analytics', 571),\n",
       " ('AI', 570),\n",
       " ('Statistics', 540),\n",
       " ('Big Data', 464),\n",
       " ('Technology', 453),\n",
       " ('Programming', 421),\n",
       " ('NLP', 343),\n",
       " ('Coronavirus', 320),\n",
       " ('Data Analytics', 301),\n",
       " ('Astrology', 241),\n",
       " ('Dailies', 228),\n",
       " ('Pandas', 224),\n",
       " ('Data Scientist', 206),\n",
       " ('Art', 201),\n",
       " ('Towards Data Science', 173),\n",
       " ('Data Engineering', 172),\n",
       " ('Neural Networks', 160),\n",
       " ('Data Science Training', 139),\n",
       " ('R', 138),\n",
       " ('Business', 134),\n",
       " ('Advertising', 134),\n",
       " ('Airbnb', 131),\n",
       " ('Dating', 130),\n",
       " ('Business Intelligence', 128),\n",
       " ('Computer Vision', 125),\n",
       " ('Mathematics', 119),\n",
       " ('Education', 118),\n",
       " ('Software Development', 117),\n",
       " ('Computer Science', 117),\n",
       " ('Python Programming', 115),\n",
       " ('Naturallanguageprocessing', 114),\n",
       " ('Visualization', 113),\n",
       " ('Algorithms', 113),\n",
       " ('Database', 109),\n",
       " ('Web Scraping', 105),\n",
       " ('Jupyter Notebook', 103),\n",
       " ('Linear Regression', 103),\n",
       " ('Travel', 103),\n",
       " ('Sql', 98),\n",
       " ('Data Mining', 97),\n",
       " ('Learning', 96),\n",
       " ('Udacity', 95),\n",
       " ('Science', 94),\n",
       " ('Python3', 93),\n",
       " ('Exploratory Data Analysis', 91),\n",
       " ('Kaggle', 90),\n",
       " ('Careers', 89),\n",
       " ('Classification', 88),\n",
       " ('AWS', 84),\n",
       " ('Coding', 82),\n",
       " ('Advice', 82),\n",
       " ('Startup', 79),\n",
       " ('Big Data Analytics', 79),\n",
       " ('Health', 78),\n",
       " ('Analysis', 78),\n",
       " ('Tutorial', 75),\n",
       " ('Healthcare', 75),\n",
       " ('Data Science Courses', 72),\n",
       " ('TensorFlow', 71),\n",
       " ('Marketing', 70),\n",
       " ('Finance', 70),\n",
       " ('Clustering', 69),\n",
       " ('Regression', 67),\n",
       " ('Tableau', 67),\n",
       " ('Interview', 66),\n",
       " ('Ciencia De Dados', 66),\n",
       " ('Engineering', 63),\n",
       " ('Pytorch', 63),\n",
       " ('Udacity Nanodegree', 62),\n",
       " ('Politics', 60),\n",
       " ('Spark', 59),\n",
       " ('Blockchain', 57),\n",
       " ('Economics', 57),\n",
       " ('Tech', 56),\n",
       " ('Predictive Analytics', 55),\n",
       " ('Logistic Regression', 55),\n",
       " ('Cloud Computing', 55),\n",
       " ('Adventure', 55),\n",
       " ('Feature Engineering', 54),\n",
       " ('Beginner', 54),\n",
       " ('Research', 54),\n",
       " ('Data Cleaning', 53),\n",
       " ('Unsupervised Learning', 53),\n",
       " ('Women In Tech', 53),\n",
       " ('Leadership', 52),\n",
       " ('Software Engineering', 52),\n",
       " ('Intelligence Artificielle', 52),\n",
       " ('Time Series Analysis', 51),\n",
       " ('Probability', 51),\n",
       " ('Astronomy', 51),\n",
       " ('Numpy', 50),\n",
       " ('Career Advice', 50),\n",
       " ('Supervised Learning', 47),\n",
       " ('Open Data', 47),\n",
       " ('Recommendation System', 46),\n",
       " ('Product Management', 46),\n",
       " ('Sentiment Analysis', 45),\n",
       " ('Decision Making', 45),\n",
       " ('R Programming', 45),\n",
       " ('API', 44),\n",
       " ('Matplotlib', 42),\n",
       " ('Web Development', 41),\n",
       " ('Decision Tree', 41),\n",
       " ('Sales', 41),\n",
       " ('Storytelling', 41),\n",
       " ('Eda', 41),\n",
       " ('Open Source', 41),\n",
       " ('Coursera', 41),\n",
       " ('Nuances Of Programming', 40),\n",
       " ('Business Strategy', 40),\n",
       " ('Reinforcement Learning', 40),\n",
       " ('Cryptocurrency', 40),\n",
       " ('Optimization', 40),\n",
       " ('India', 40),\n",
       " ('Pandemic', 40),\n",
       " ('DevOps', 39),\n",
       " ('Microsoft', 39),\n",
       " ('Corona', 39),\n",
       " ('JavaScript', 38),\n",
       " ('Google', 38),\n",
       " ('Time Series Forecasting', 38),\n",
       " ('Privacy', 38),\n",
       " ('Bootcamp', 38),\n",
       " ('Challenge', 38),\n",
       " ('Rstudio', 37),\n",
       " ('Power Bi', 37),\n",
       " ('Digital Transformation', 37),\n",
       " ('Twitter', 37),\n",
       " ('Addiction', 37),\n",
       " ('News', 36),\n",
       " ('Innovation', 36),\n",
       " ('Image Processing', 36),\n",
       " ('Automation', 36),\n",
       " ('Sports', 36),\n",
       " ('Statistical Analysis', 35),\n",
       " ('Starbucks', 35),\n",
       " ('Convolutional Network', 35),\n",
       " ('Pandas Dataframe', 34),\n",
       " ('Forecasting', 34),\n",
       " ('Scikit Learn', 33),\n",
       " ('Data Preprocessing', 33),\n",
       " ('Modeling', 33),\n",
       " ('Google Cloud Platform', 33),\n",
       " ('Predictions', 32),\n",
       " ('Cybersecurity', 32),\n",
       " ('Dashboard', 32),\n",
       " ('Inteligencia Artificial', 31),\n",
       " ('Docker', 31),\n",
       " ('Data Analyst', 31),\n",
       " ('Keras', 31),\n",
       " ('Jobs', 30),\n",
       " ('Career Change', 30),\n",
       " ('Azure', 30),\n",
       " ('Geospatial', 30),\n",
       " ('Music', 30),\n",
       " ('Projects', 30),\n",
       " ('Public Health', 30),\n",
       " ('IoT', 29),\n",
       " ('Random Forest', 29),\n",
       " ('Business Analysis', 29),\n",
       " ('Classification Algorithms', 29),\n",
       " ('Management', 28),\n",
       " ('Business Analytics', 28),\n",
       " ('Productivity', 28),\n",
       " ('Football', 28),\n",
       " ('Digital Marketing', 28),\n",
       " ('Investing', 28),\n",
       " ('Predictive Modeling', 28),\n",
       " ('Stock Market', 28),\n",
       " ('K Means', 27),\n",
       " ('Social Media', 27),\n",
       " ('Seattle', 27),\n",
       " ('Ecommerce', 27),\n",
       " ('Veri Bilimi', 27),\n",
       " ('Object Detection', 26),\n",
       " ('Bitcoin', 26),\n",
       " ('Apache Spark', 26),\n",
       " ('Retail', 26),\n",
       " ('Confusion Matrix', 26),\n",
       " ('Psychology', 26),\n",
       " ('IBM', 26),\n",
       " ('K Means Clustering', 25),\n",
       " ('Movies', 25),\n",
       " ('Hypothesis Testing', 25),\n",
       " ('Internships', 25),\n",
       " ('Mlops', 25),\n",
       " ('Flask', 25),\n",
       " ('Course', 25),\n",
       " ('Plotly', 25),\n",
       " ('Beautifulsoup', 25),\n",
       " ('Ethics', 25),\n",
       " ('Interview Questions', 25),\n",
       " ('Covid 19 Crisis', 25),\n",
       " ('Podcast', 24),\n",
       " ('Seaborn', 24),\n",
       " ('Beginners Guide', 24),\n",
       " ('Chatbots', 24),\n",
       " ('Trends', 23),\n",
       " ('Recommender Systems', 23),\n",
       " ('Maps', 23),\n",
       " ('Regression Analysis', 23),\n",
       " ('Text Mining', 23),\n",
       " ('Hadoop', 23),\n",
       " ('Fintech', 23),\n",
       " ('Strategy', 23),\n",
       " ('Online Learning', 23),\n",
       " ('Design', 23),\n",
       " ('Elections', 23),\n",
       " ('Linear Algebra', 23),\n",
       " ('Excel', 22),\n",
       " ('Anaconda', 22),\n",
       " ('Dataset', 22),\n",
       " ('Boston', 22),\n",
       " ('Climate Change', 22),\n",
       " ('Automl', 22),\n",
       " ('Bias', 22),\n",
       " ('Neuroscience', 22),\n",
       " ('Image Classification', 22),\n",
       " ('Covid-19', 22),\n",
       " ('Future', 21),\n",
       " ('Trading', 21),\n",
       " ('Data Driven', 21),\n",
       " ('Security', 21),\n",
       " ('Training', 21),\n",
       " ('Entrepreneurship', 21),\n",
       " ('Machine Learning Ai', 21),\n",
       " ('Análise De Dados', 21),\n",
       " ('Sports Analytics', 21),\n",
       " ('Github', 21),\n",
       " ('Capstone Project', 21),\n",
       " ('Job Hunting', 21),\n",
       " ('Project Management', 20),\n",
       " ('Machine Intelligence', 20),\n",
       " ('Cloud', 20),\n",
       " ('Data Visualisation', 20),\n",
       " ('Java', 20),\n",
       " ('Consulting', 20),\n",
       " ('Africa', 20),\n",
       " ('Deployment', 20),\n",
       " ('數據分析', 20),\n",
       " ('Books', 20),\n",
       " ('Online Courses', 20),\n",
       " ('Learning To Code', 20),\n",
       " ('Medicine', 19),\n",
       " ('Food', 19),\n",
       " ('Xgboost', 19),\n",
       " ('Spotify', 19),\n",
       " ('Pyspark', 19),\n",
       " ('Journalism', 19),\n",
       " ('Coffee', 19),\n",
       " ('Heartbeat', 19),\n",
       " ('NBA', 19),\n",
       " ('Information Technology', 19),\n",
       " ('Math', 19),\n",
       " ('Epidemiology', 19),\n",
       " ('Media', 18),\n",
       " ('Data Journalism', 18),\n",
       " ('Opencv', 18),\n",
       " ('Customer Segmentation', 18),\n",
       " ('Agile', 18),\n",
       " ('UX', 18),\n",
       " ('Sklearn', 18),\n",
       " ('Linux', 18),\n",
       " ('Venture Capital', 18),\n",
       " ('Development', 18),\n",
       " ('Etl', 18),\n",
       " ('Data Modeling', 18),\n",
       " ('Stackoverflow', 18),\n",
       " ('Programming Languages', 18),\n",
       " ('Rio De Janeiro', 18),\n",
       " ('Data Scraping', 18),\n",
       " ('Matlab', 18),\n",
       " ('Charts', 17),\n",
       " ('Topic Modeling', 17),\n",
       " ('Ensemble Learning', 17),\n",
       " ('Dimensionality Reduction', 17),\n",
       " ('Kaggle Competition', 17),\n",
       " ('Testing', 17),\n",
       " ('Data Pipeline', 17),\n",
       " ('Developer', 17),\n",
       " ('Ethereum', 17),\n",
       " ('Data Structures', 17),\n",
       " ('Crisp Dm', 17),\n",
       " ('Ds In The Real World', 17),\n",
       " ('Knn', 17),\n",
       " ('Graph', 17),\n",
       " ('Racism', 17),\n",
       " ('Blog', 17),\n",
       " ('Data Management', 17),\n",
       " ('Artist', 17),\n",
       " ('Knn Algorithm', 17),\n",
       " ('Ab Testing', 16),\n",
       " ('Growth', 16),\n",
       " ('Netflix', 16),\n",
       " ('Explainable Ai', 16),\n",
       " ('Kubernetes', 16),\n",
       " ('Metrics', 16),\n",
       " ('Real Estate', 16),\n",
       " ('Anomaly Detection', 16),\n",
       " ('Energy', 16),\n",
       " ('Bayesian Statistics', 16),\n",
       " ('Datascience Certification', 16),\n",
       " ('Gradient Descent', 16),\n",
       " ('Naive Bayes', 16),\n",
       " ('Self Improvement', 16),\n",
       " ('Facebook', 16),\n",
       " ('Indonesia', 16),\n",
       " ('Dados', 16),\n",
       " ('About', 16),\n",
       " ('Lockdown', 16),\n",
       " ('Google Colab', 15),\n",
       " ('Certification', 15),\n",
       " ('Correlation', 15),\n",
       " ('Workflow', 15),\n",
       " ('General Assembly', 15),\n",
       " ('Data Preparation', 15),\n",
       " ('Charity', 15),\n",
       " ('Flatiron School', 15),\n",
       " ('Data Collection', 15),\n",
       " ('Virus', 15),\n",
       " ('Insights', 15),\n",
       " ('Dataops', 14),\n",
       " ('Missing Data', 14),\n",
       " ('Mobility', 14),\n",
       " ('Data Wrangling', 14),\n",
       " ('Jupyter', 14),\n",
       " ('Estatistica', 14),\n",
       " ('Data Storytelling', 14),\n",
       " ('Data Lake', 14),\n",
       " ('Environment', 14),\n",
       " ('Ciência De Dados', 14),\n",
       " ('Julia', 14),\n",
       " ('Gpu', 14),\n",
       " ('Customer Experience', 14),\n",
       " ('Containers', 14),\n",
       " ('Espresso', 14),\n",
       " ('Students', 14),\n",
       " ('Data Warehouse', 14),\n",
       " ('Platform', 14),\n",
       " ('Churn Prediction', 14),\n",
       " ('Co Vid 19', 14),\n",
       " ('Hackathons', 13),\n",
       " ('Hiring', 13),\n",
       " ('Lstm', 13),\n",
       " ('Brasil', 13),\n",
       " ('Crossvalidation', 13),\n",
       " ('Timeseries', 13),\n",
       " ('Skills', 13),\n",
       " ('Career Development', 13),\n",
       " ('Churn', 13),\n",
       " ('Marketing Strategies', 13),\n",
       " ('Code', 13),\n",
       " ('Recommendations', 13),\n",
       " ('Datacamp', 13),\n",
       " ('Codingbootcamp', 13),\n",
       " ('Collaboration', 13),\n",
       " ('Policy', 13),\n",
       " ('Reading', 13),\n",
       " ('Data Strategy', 13),\n",
       " ('Life', 13),\n",
       " ('Segmentation', 13),\n",
       " ('Bigquery', 13),\n",
       " ('Tecnologia', 13),\n",
       " ('Word Embeddings', 13),\n",
       " ('Mental Health', 13),\n",
       " ('GIS', 12),\n",
       " ('Airflow', 12),\n",
       " ('Women In Data Science', 12),\n",
       " ('Datascience Training', 12),\n",
       " ('Simulation', 12),\n",
       " ('Data Processing', 12),\n",
       " ('Bioinformatics', 12),\n",
       " ('Soccer', 12),\n",
       " ('Descriptive Statistics', 12),\n",
       " ('Support Vector Machine', 12),\n",
       " ('Artificial Neural Network', 12),\n",
       " ('Infographics', 12),\n",
       " ('SaaS', 12),\n",
       " ('Data Driven Decisions', 12),\n",
       " ('Selenium', 12),\n",
       " ('Model', 12),\n",
       " ('Future Of Work', 12),\n",
       " ('Weeknotes', 12),\n",
       " ('Statistical Learning', 12),\n",
       " ('Case Study', 12),\n",
       " ('Supply Chain', 12),\n",
       " ('Guides And Tutorials', 12),\n",
       " ('Crime', 12),\n",
       " ('Community', 12),\n",
       " ('Carreira', 12),\n",
       " ('Digital', 12),\n",
       " ('Data Exploration', 12),\n",
       " ('Neo4j', 12),\n",
       " ('Heroku', 12),\n",
       " ('Asia', 12),\n",
       " ('Quarantine', 12),\n",
       " ('K Nearest Neighbours', 12),\n",
       " ('Opencv Python', 11),\n",
       " ('Dataframes', 11),\n",
       " ('Problem Solving', 11),\n",
       " ('Competition', 11),\n",
       " ('Git', 11),\n",
       " ('History', 11),\n",
       " ('Government', 11),\n",
       " ('Transportation', 11),\n",
       " ('Econometrics', 11),\n",
       " ('Software', 11),\n",
       " ('Heart Disease', 11),\n",
       " ('A B Testing', 11),\n",
       " ('Satellite Imagery', 11),\n",
       " ('User Experience', 11),\n",
       " ('Overfitting', 11),\n",
       " ('Folium', 11),\n",
       " ('R Language', 11),\n",
       " ('Data Science Institute', 11),\n",
       " ('Inspiration', 11),\n",
       " ('Streamlit', 11),\n",
       " ('Product', 11),\n",
       " ('Datasciencecourse', 11),\n",
       " ('Web Data', 11),\n",
       " ('Tds Event Talk', 11),\n",
       " ('Data Engineer', 11),\n",
       " ('Rstats', 11),\n",
       " ('Free', 11),\n",
       " ('United States', 11),\n",
       " ('Adoption', 11),\n",
       " ('Experiment', 10),\n",
       " ('Review', 10),\n",
       " ('Graduate School', 10),\n",
       " ('Experimentation', 10),\n",
       " ('Image Recognition', 10),\n",
       " ('Culture', 10),\n",
       " ('Data Science Job', 10),\n",
       " ('Analytics Vidhya', 10),\n",
       " ('Life Lessons', 10),\n",
       " ('Feature Selection', 10),\n",
       " ('2020', 10),\n",
       " ('Data Quality', 10),\n",
       " ('Market Basket Analysis', 10),\n",
       " ('Gaming', 10),\n",
       " ('Machine Learning Tools', 10),\n",
       " ('Baseball', 10),\n",
       " ('Surveys', 10),\n",
       " ('MySQL', 10),\n",
       " ('Scraping', 10),\n",
       " ('Causality', 10),\n",
       " ('Growth Hacking', 10),\n",
       " ('Data Science Careers', 10),\n",
       " ('Bert', 10),\n",
       " ('Architecture', 10),\n",
       " ('Timeseries Forecasting', 10),\n",
       " ('Teamwork', 10),\n",
       " ('Economy', 10),\n",
       " ('Bias Variance Tradeoff', 10),\n",
       " ('Learn Data Science', 10),\n",
       " ('Manufacturing', 10),\n",
       " ('Text Analytics', 10),\n",
       " ('Happiness', 10),\n",
       " ('Inferential Statistics', 10),\n",
       " ('Design Thinking', 10),\n",
       " ('Cnn', 10),\n",
       " ('Motivation', 10),\n",
       " ('Elasticsearch', 10),\n",
       " ('Banking', 10),\n",
       " ('Internet', 10),\n",
       " ('USA', 10),\n",
       " ('Internet of Things', 10),\n",
       " ('Word2vec', 10),\n",
       " ('Capstone', 10),\n",
       " ('Experience', 10),\n",
       " ('Fake News', 10),\n",
       " ('Ciencia De Datos', 10),\n",
       " ('Learnbay', 10),\n",
       " ('Svm', 10),\n",
       " ('BlackLivesMatter', 10),\n",
       " ('Aesthetics', 10),\n",
       " ('NFL', 9),\n",
       " ('Money', 9),\n",
       " ('Face Recognition', 9),\n",
       " ('Streaming', 9),\n",
       " ('Natural Language Process', 9),\n",
       " ('Advanced Analytics', 9),\n",
       " ('Csv', 9),\n",
       " ('Pipeline', 9),\n",
       " ('Salary', 9),\n",
       " ('Lambda School', 9),\n",
       " ('Convolution Neural Net', 9),\n",
       " ('Infrastructure', 9),\n",
       " ('Performance', 9),\n",
       " ('Housing', 9),\n",
       " ('Transfer Learning', 9),\n",
       " ('Cricket', 9),\n",
       " ('Data Governance', 9),\n",
       " ('Arima', 9),\n",
       " ('Mapping', 9),\n",
       " ('Serverless', 9),\n",
       " ('Data Pre Processing', 9),\n",
       " ('Future Technology', 9),\n",
       " ('Tools', 9),\n",
       " ('Data Privacy', 9),\n",
       " ('Español', 9),\n",
       " ('Freelancing', 9),\n",
       " ('Renewable Energy', 9),\n",
       " ('Co-op', 9),\n",
       " ('Program Website', 9),\n",
       " ('Data Architecture', 9),\n",
       " ('Robotics', 9),\n",
       " ('Bi', 9),\n",
       " ('World', 9),\n",
       " ('Shecodeafrica', 9),\n",
       " ('Public Policy', 9),\n",
       " ('Foursquare', 9),\n",
       " ('Open Source Software', 9),\n",
       " ('Hacking', 9),\n",
       " ('Dataviz', 9),\n",
       " ('Bayes Theorem', 9),\n",
       " ('China', 9),\n",
       " ('Data Scientist Skills', 9),\n",
       " ('Online', 9),\n",
       " ('Blockchain Technology', 9),\n",
       " ('Saudi Arabia', 9),\n",
       " ('Scala', 9),\n",
       " ('Location Intelligence', 9),\n",
       " ('Cars', 9),\n",
       " ('Spanish', 9),\n",
       " ('DIY', 9),\n",
       " ('Datascienceinstitute', 9),\n",
       " ('Philosophy', 9),\n",
       " ('Personal Development', 9),\n",
       " ('Self Driving Cars', 9),\n",
       " ('Covid 19 Testing', 9),\n",
       " ('Investment', 9),\n",
       " ('Asian American', 9),\n",
       " ('Geography', 8),\n",
       " ('Diversity', 8),\n",
       " ('Nltk', 8),\n",
       " ('Colab', 8),\n",
       " ('Content', 8),\n",
       " ('Dataanalys', 8),\n",
       " ('Data For Good', 8),\n",
       " ('ML', 8),\n",
       " ('Fraud Detection', 8),\n",
       " ('Weather', 8),\n",
       " ('Writing', 8),\n",
       " ('Resume', 8),\n",
       " ('Sustainability', 8),\n",
       " ('Data Analytics Tools', 8),\n",
       " ('Imbalanced Data', 8),\n",
       " ('Google Analytics', 8),\n",
       " ('Clustering Algorithm', 8),\n",
       " ('Ggplot2', 8),\n",
       " ('Biostatistics', 8),\n",
       " ('Conference', 8),\n",
       " ('Videogames', 8),\n",
       " ('Alternative Data', 8),\n",
       " ('Product Design', 8),\n",
       " ('Apps', 8),\n",
       " ('Ml Model Deployment', 8),\n",
       " ('Gradient Boosting', 8),\n",
       " ('Dash', 8),\n",
       " ('Wine', 8),\n",
       " ('WhatsApp', 8),\n",
       " ('Aprendizado De Maquina', 8),\n",
       " ('NYU', 8),\n",
       " ('Artificalintelligence', 8),\n",
       " ('UX Research', 8),\n",
       " ('Gdpr', 8),\n",
       " ('Deeplearing', 8),\n",
       " ('Fashion', 8),\n",
       " ('UX Design', 8),\n",
       " ('Oil And Gas', 8),\n",
       " ('Biotechnology', 8),\n",
       " ('Job Search', 8),\n",
       " ('Fastai', 8),\n",
       " ('Biomedical', 8),\n",
       " ('Recruiting', 8),\n",
       " ('Visit blog.datatron.com', 8),\n",
       " ('Data Science Marketer', 8),\n",
       " ('Algorithmic Trading', 8),\n",
       " ('P Value', 8),\n",
       " ('Makine Öğrenmesi', 8),\n",
       " ('Yolo', 8),\n",
       " ('Machine Learning ', 8),\n",
       " ('Catapult Data Leaders', 8),\n",
       " ('Editors Pick', 8),\n",
       " ('Search', 7),\n",
       " ('Generative Adversarial', 7),\n",
       " ('Text Analysis', 7),\n",
       " ('University', 7),\n",
       " ('Cancer', 7),\n",
       " ('Naive Bayes Classifier', 7),\n",
       " ('Akshaj Wields Pytorch', 7),\n",
       " ('Data Manipulation', 7),\n",
       " ('Precision', 7),\n",
       " ('Inside Ai', 7),\n",
       " ('Hyperparameter Tuning', 7),\n",
       " ('Relationships', 7),\n",
       " ('Communication', 7),\n",
       " ('Energy Efficiency', 7),\n",
       " ('No Code', 7),\n",
       " ('New York', 7),\n",
       " ('Classification Models', 7),\n",
       " ('Aritificial Intelligence', 7),\n",
       " ('Reflections', 7),\n",
       " ('Image', 7),\n",
       " ('YouTube', 7),\n",
       " ('Data Scientist Career', 7),\n",
       " ('Model Evaluation', 7),\n",
       " ('Collaborative Filtering', 7),\n",
       " ('Model Interpretability', 7),\n",
       " ('Nigeria', 7),\n",
       " ('Outliers', 7),\n",
       " ('Geoscience', 7),\n",
       " ('Work', 7),\n",
       " ('Federated Learning', 7),\n",
       " ('Marketing Analytics', 7),\n",
       " ('Edtech', 7),\n",
       " ('Quant', 7),\n",
       " ('First Post', 7),\n",
       " ('Career Paths', 7),\n",
       " ('How To', 7),\n",
       " ('Human Resources', 7),\n",
       " ('Biology', 7),\n",
       " ('Search Engines', 7),\n",
       " ('Causal Inference', 7),\n",
       " ('Academia', 7),\n",
       " ('Basketball', 7),\n",
       " ('Convolutional Neural Net', 7),\n",
       " ('Social Science', 7),\n",
       " ('Enterprise Technology', 7),\n",
       " ('Estatísticas', 7),\n",
       " ('Remote Working', 7),\n",
       " ('Trump', 7),\n",
       " ('Django', 7),\n",
       " ('Events', 7),\n",
       " ('Variance', 7),\n",
       " ('Word Cloud', 7),\n",
       " ('Spatial Analysis', 7),\n",
       " ('Padhai', 7),\n",
       " ('Board Games', 7),\n",
       " ('Data Literacy', 7),\n",
       " ('Business Analyst', 7),\n",
       " ('Stackoverflow Survey', 7),\n",
       " ('Parallel Computing', 7),\n",
       " ('Geopandas', 7),\n",
       " ('Healthcare Technology', 7),\n",
       " ('Insight Data Science', 7),\n",
       " ('Smart Cities', 7),\n",
       " ('Apple', 7),\n",
       " ('Italy', 7),\n",
       " ('Python Data Science', 7),\n",
       " ('Public Transport', 7),\n",
       " ('Mexico', 7),\n",
       " ('Korona', 7),\n",
       " ('Dotnet', 7),\n",
       " ('Customer', 7),\n",
       " ('Graph Analytics', 7),\n",
       " ('Industry', 7),\n",
       " ('Google Trends', 7),\n",
       " ('Accessibility', 7),\n",
       " ('Machine Learning Python', 7),\n",
       " ('Aviation', 7),\n",
       " ('Databricks', 7),\n",
       " ('365 Data Science', 7),\n",
       " ('Techlab', 7),\n",
       " ('Creativity', 6),\n",
       " ('Intern', 6),\n",
       " ('Network', 6),\n",
       " ('Pca', 6),\n",
       " ('Bokeh', 6),\n",
       " ('Cientista De Dados', 6),\n",
       " ('Data Science Projects', 6),\n",
       " ('Fraud', 6),\n",
       " ('Knime', 6),\n",
       " ('Survival Analysis', 6),\n",
       " ('Machinelearning', 6),\n",
       " ('Bitgrit', 6),\n",
       " ('Career', 6),\n",
       " ('All', 6),\n",
       " ('Stocks', 6),\n",
       " ('It', 6),\n",
       " ('Women', 6),\n",
       " ('Success', 6),\n",
       " ('Activation Functions', 6),\n",
       " ('Business Development', 6),\n",
       " ('Toronto', 6),\n",
       " ('Predictive Maintenance', 6),\n",
       " ('Transformers', 6),\n",
       " ('Mathematical Modeling', 6),\n",
       " ('Journey', 6),\n",
       " ('Brain', 6),\n",
       " ('Uc Berkeley', 6),\n",
       " ('Sigmoid', 6),\n",
       " ('Presentations', 6),\n",
       " ('People Analytics', 6),\n",
       " ('Machine Lear', 6),\n",
       " ('Behavioral Economics', 6),\n",
       " ('Networking', 6),\n",
       " ('Pollution', 6),\n",
       " ('Agriculture', 6),\n",
       " ('Data Security', 6),\n",
       " ('Customer Analytics', 6),\n",
       " ('Vozes', 6),\n",
       " ('Normal Distribution', 6),\n",
       " ('Brazil', 6),\n",
       " ('Rapids Ai', 6),\n",
       " ('Data Science For Ml', 6),\n",
       " ('Ciencia Y Datos', 6),\n",
       " ('Technology News', 6),\n",
       " ('Data Science Course', 6),\n",
       " ('Enterprise Data', 6),\n",
       " ('Courses And Training', 6),\n",
       " ('HR', 6),\n",
       " ('Botnoi', 6),\n",
       " ('Titanic', 6),\n",
       " ('Berlin', 6),\n",
       " ('Product Development', 6),\n",
       " ('Knowledge', 6),\n",
       " ('Film', 6),\n",
       " ('Principal Component', 6),\n",
       " ('Meta Learning', 6),\n",
       " ('Medical', 6),\n",
       " ('Text Classification', 6),\n",
       " ('Remote Sensing', 6),\n",
       " ('Data Scraping Software', 6),\n",
       " ('Automotive', 6),\n",
       " ('Alteryx', 6),\n",
       " ('Introduction', 6),\n",
       " ('Amazon', 6),\n",
       " ('Distribution', 6),\n",
       " ('Continuous Integration', 6),\n",
       " ('Bus', 6),\n",
       " ('Operations Research', 6),\n",
       " ('Arvato', 6),\n",
       " ('Learning And Development', 6),\n",
       " ('Apriori Algorithm', 6),\n",
       " ('Mobile App Development', 6),\n",
       " ('Ireland', 6),\n",
       " ('Data Extraction', 6),\n",
       " ('Veribilimicat', 6),\n",
       " ('Personalization', 6),\n",
       " ('Datasciencecoursedelhi', 6),\n",
       " ('Webinar', 6),\n",
       " ('Germany', 6),\n",
       " ('Australia', 6),\n",
       " ('Spain', 6),\n",
       " ('Housing Prices', 6),\n",
       " ('Boosting', 6),\n",
       " ('Career In Data Science', 6),\n",
       " ('Restaurant', 6),\n",
       " ('Gadgets', 6),\n",
       " ('Android', 6),\n",
       " ('Tennis', 6),\n",
       " ('Satire', 6),\n",
       " ('Sd', 6),\n",
       " ('Cluster Analysis', 5),\n",
       " ('Getting Started', 5),\n",
       " ('Python For Data Science', 5),\n",
       " ('Sociology', 5),\n",
       " ('Modelling And Simulation', 5),\n",
       " ('Image Segmentation', 5),\n",
       " ('D3js', 5),\n",
       " ('Snowflake', 5),\n",
       " ('Hierarchical Clustering', 5),\n",
       " ('Leadership Development', 5),\n",
       " ('Framework', 5),\n",
       " ('Interview Preparation', 5),\n",
       " ('Physics', 5),\n",
       " ('Missing Values', 5),\n",
       " ('Recall', 5),\n",
       " ('Data Integration', 5),\n",
       " ('Soccer Analytics', 5),\n",
       " ('Hedge Funds', 5),\n",
       " ('Electric Vehicles', 5),\n",
       " ('Fleet Management', 5),\n",
       " ('AWS Lambda', 5),\n",
       " ('Singapore', 5),\n",
       " ('Customer Churn', 5),\n",
       " ('Startup Lessons', 5),\n",
       " ('Sales Forecasting', 5),\n",
       " ('Study', 5),\n",
       " ('Political Science', 5),\n",
       " ('Governance', 5),\n",
       " ('Anova', 5),\n",
       " ('Analyst', 5),\n",
       " ('Online Education', 5),\n",
       " ('Histograms', 5),\n",
       " ('Wildlife Studios', 5),\n",
       " ('Interview Tips', 5),\n",
       " ('Lda', 5),\n",
       " ('Time Series Data', 5),\n",
       " ('Book Review', 5),\n",
       " ('Newsletter', 5),\n",
       " ('Simple Linear Regression', 5),\n",
       " ('Autoencoder', 5),\n",
       " ('STEM', 5),\n",
       " ('Systems Thinking', 5),\n",
       " ('Pricing', 5),\n",
       " ('Malware', 5),\n",
       " ('Linear Regression Python', 5),\n",
       " ('Blog Post', 5),\n",
       " ('Higher Education', 5),\n",
       " ('Production', 5),\n",
       " ('Ideas', 5),\n",
       " ('Virtual Environment', 5),\n",
       " ('Adobe Experience Platform', 5),\n",
       " ('R Programming Language', 5),\n",
       " ('Scrapy', 5),\n",
       " ('Veri', 5),\n",
       " ('Growth Mindset', 5),\n",
       " ('Shopify', 5),\n",
       " ('Data Science Bootcamp', 5),\n",
       " ('Satellite Technology', 5),\n",
       " ('Afl', 5),\n",
       " ('House Prices', 5),\n",
       " ('Feature Scaling', 5),\n",
       " ('Cities', 5),\n",
       " ('Information Retrieval', 5),\n",
       " ('Resnet', 5),\n",
       " ('Multi Armed Bandit', 5),\n",
       " ('Uber', 5),\n",
       " ('Mean', 5),\n",
       " ('Social Impact', 5),\n",
       " ('Regularization', 5),\n",
       " ('Análise', 5),\n",
       " ('Process', 5),\n",
       " ('LinkedIn', 5),\n",
       " ('Announcements', 5),\n",
       " ('Crypto', 5),\n",
       " ('Prophet', 5),\n",
       " ('Fbprophet', 5),\n",
       " ('Information', 5),\n",
       " ('Qlik', 5),\n",
       " ('Recruitment', 5),\n",
       " ('Machine', 5),\n",
       " ('People', 5),\n",
       " ('Personal Growth', 5),\n",
       " ('Data Science Mumbai', 5),\n",
       " ('Intel', 5),\n",
       " ('In Depth Analysis', 5),\n",
       " ('Installation', 5),\n",
       " ('Central Limit Theorem', 5),\n",
       " ('Boardgamegeek', 5),\n",
       " ('Anaconda Navigator', 5),\n",
       " ('Bahasa Indonesia', 5),\n",
       " ('Logistics', 5),\n",
       " ('Web Data Scraper', 5),\n",
       " ('Decision Tree Classifier', 5),\n",
       " ('Decision Tree Regressor', 5),\n",
       " ('Cool Stuff', 5),\n",
       " ('Space', 5),\n",
       " ('FIFA', 5),\n",
       " ('Covid', 5),\n",
       " ('Customer Success', 5),\n",
       " ('Mlflow', 5),\n",
       " ('Wearables', 5),\n",
       " ('Tds Event Talks', 5),\n",
       " ('Scrum', 5),\n",
       " ('Vienna', 5),\n",
       " ('Apriori', 5),\n",
       " ('Tech For Good', 5),\n",
       " ('Disease', 5),\n",
       " ('Earth Observation', 5),\n",
       " ('Pandemia', 5),\n",
       " ('Population', 5),\n",
       " ('Handling Missing Values', 5),\n",
       " ('Postgres', 5),\n",
       " ('NoSQL', 5),\n",
       " ('Gans', 5),\n",
       " ('E Commerce Business', 5),\n",
       " ('NYC', 5),\n",
       " ('Risk Management', 5),\n",
       " ('Customer Engagement', 5),\n",
       " ('Datascienceinstitutedelhi', 5),\n",
       " ('Rfm Analysis', 5),\n",
       " ('Nanodegree', 5),\n",
       " ('Competitive Programming', 5),\n",
       " ('Machie Learning', 5),\n",
       " ('Complexity', 5),\n",
       " ('Functional Programming', 5),\n",
       " ('Estadística', 5),\n",
       " ('Microsoft Azure', 5),\n",
       " ('Customer Service', 5),\n",
       " ('Visualisation', 5),\n",
       " ('Global Health', 5),\n",
       " ('Nonprofit', 5),\n",
       " ('Duke University', 5),\n",
       " ('User Research', 5),\n",
       " ('Roadmaps', 5),\n",
       " ('Programação', 5),\n",
       " ('Cheatsheet', 5),\n",
       " ('Osint', 5),\n",
       " ('Bots', 5),\n",
       " ('Portfolio', 5),\n",
       " ('Xai', 5),\n",
       " ('Ngrams', 5),\n",
       " ('Deepfakes', 5),\n",
       " ('Data Infrastructure', 5),\n",
       " ('Neural Network', 5),\n",
       " ('House Price Prediction', 5),\n",
       " ('Modelling', 5),\n",
       " ('Alibabacloud', 5),\n",
       " ('Evaluation', 5),\n",
       " ('Knowledge Management', 5),\n",
       " ('Software Architecture', 5),\n",
       " ('Election 2020', 5),\n",
       " ('Pandas Series', 5),\n",
       " ('Médium', 5),\n",
       " ('OpenAI', 5),\n",
       " ('Angular', 5),\n",
       " ('Super Bowl', 4),\n",
       " ('R Shiny', 4),\n",
       " ('Insurance', 4),\n",
       " ('Generative Model', 4),\n",
       " ('Optimization Algorithms', 4),\n",
       " ('Cannabis', 4),\n",
       " ('2020 Presidential Race', 4),\n",
       " ('UK', 4),\n",
       " ('Information Theory', 4),\n",
       " ('Central Tendency', 4),\n",
       " ('Probability Distributions', 4),\n",
       " ('Monte Carlo', 4),\n",
       " ('Internship Experience', 4),\n",
       " ('Spacy', 4),\n",
       " ('Amazon Sagemaker', 4),\n",
       " ('Quality Assurance', 4),\n",
       " ('Dengue', 4),\n",
       " ('Soft Skills', 4),\n",
       " ('Electric Car', 4),\n",
       " ('Deploy', 4),\n",
       " ('Traffic', 4),\n",
       " ('Kafka', 4),\n",
       " ('Dask', 4),\n",
       " ('Data Labeling', 4),\n",
       " ('Real Time Analytics', 4),\n",
       " ('Pokemon', 4),\n",
       " ('資料科學', 4),\n",
       " ('Subscription', 4),\n",
       " ('Version Control', 4),\n",
       " ('Shiny', 4),\n",
       " ('Hypothesis', 4),\n",
       " ('Command Line', 4),\n",
       " ('Debugging', 4),\n",
       " ('Telecom', 4),\n",
       " ('Zomato', 4),\n",
       " ('Json', 4),\n",
       " ('Fitness', 4),\n",
       " ('Web', 4),\n",
       " ('Hindi', 4),\n",
       " ('Instagram', 4),\n",
       " ('Wimlds', 4),\n",
       " ('Facebook Prophet', 4),\n",
       " ('Tf Idf', 4),\n",
       " ('Time Series', 4),\n",
       " ('Ocr', 4),\n",
       " ('Price Prediction', 4),\n",
       " ('Music Business', 4),\n",
       " ('Feminism', 4),\n",
       " ('Libraries', 4),\n",
       " ('Datetime', 4),\n",
       " ('Retail Technology', 4),\n",
       " ('Meetup', 4),\n",
       " ('Sampling', 4),\n",
       " ('Best Practices', 4),\n",
       " ('Health Technology', 4),\n",
       " ('Interpretability', 4),\n",
       " ('Analytics Platforms', 4),\n",
       " ('Sports Betting', 4),\n",
       " ('Feature Stories', 4),\n",
       " ('More', 4),\n",
       " ('Meteorology', 4),\n",
       " ('Msba', 4),\n",
       " ('Mooc', 4),\n",
       " ('Geospatial Data', 4),\n",
       " ('Retail Analytics', 4),\n",
       " ('Urban Planning', 4),\n",
       " ('Women in STEM', 4),\n",
       " ('Airlines', 4),\n",
       " ('Air Pollution', 4),\n",
       " ('Data Ethics', 4),\n",
       " ('Rock Climbing', 4),\n",
       " ('Conversion Optimization', 4),\n",
       " ('Credit Cards', 4),\n",
       " ('Salesforce', 4),\n",
       " ('Fantasy Football', 4),\n",
       " ('Epidemic', 4),\n",
       " ('Credit', 4),\n",
       " ('Mallet', 4),\n",
       " ('Oracle', 4),\n",
       " ('Python Libraries', 4),\n",
       " ('Prefect', 4),\n",
       " ('數據', 4),\n",
       " ...]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the amount of time an article shows up in descending order\n",
    "sort_orders = sorted(tag_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sort_orders = sort_orders[1:] # remove the 'Data Science' tag since it shows up in every article\n",
    "sort_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Machine Learning': 4040,\n",
       " 'Python': 1748,\n",
       " 'Artificial Intelligence': 1714,\n",
       " 'Data Visualization': 1184,\n",
       " 'Data': 1077,\n",
       " 'Deep Learning': 812,\n",
       " 'Covid 19': 637,\n",
       " 'Data Analysis': 630,\n",
       " 'Analytics': 571,\n",
       " 'AI': 570,\n",
       " 'Statistics': 540,\n",
       " 'Big Data': 464,\n",
       " 'Technology': 453,\n",
       " 'Programming': 421,\n",
       " 'NLP': 343,\n",
       " 'Coronavirus': 320,\n",
       " 'Data Analytics': 301,\n",
       " 'Astrology': 241,\n",
       " 'Dailies': 228,\n",
       " 'Pandas': 224,\n",
       " 'Data Scientist': 206,\n",
       " 'Art': 201,\n",
       " 'Towards Data Science': 173,\n",
       " 'Data Engineering': 172,\n",
       " 'Neural Networks': 160,\n",
       " 'Data Science Training': 139,\n",
       " 'R': 138,\n",
       " 'Business': 134,\n",
       " 'Advertising': 134,\n",
       " 'Airbnb': 131,\n",
       " 'Dating': 130,\n",
       " 'Business Intelligence': 128,\n",
       " 'Computer Vision': 125,\n",
       " 'Mathematics': 119,\n",
       " 'Education': 118,\n",
       " 'Software Development': 117,\n",
       " 'Computer Science': 117,\n",
       " 'Python Programming': 115,\n",
       " 'Naturallanguageprocessing': 114,\n",
       " 'Visualization': 113,\n",
       " 'Algorithms': 113,\n",
       " 'Database': 109,\n",
       " 'Web Scraping': 105,\n",
       " 'Jupyter Notebook': 103,\n",
       " 'Linear Regression': 103,\n",
       " 'Travel': 103,\n",
       " 'Sql': 98,\n",
       " 'Data Mining': 97,\n",
       " 'Learning': 96,\n",
       " 'Udacity': 95,\n",
       " 'Science': 94,\n",
       " 'Python3': 93,\n",
       " 'Exploratory Data Analysis': 91,\n",
       " 'Kaggle': 90,\n",
       " 'Careers': 89,\n",
       " 'Classification': 88,\n",
       " 'AWS': 84,\n",
       " 'Coding': 82,\n",
       " 'Advice': 82,\n",
       " 'Startup': 79,\n",
       " 'Big Data Analytics': 79,\n",
       " 'Health': 78,\n",
       " 'Analysis': 78,\n",
       " 'Tutorial': 75,\n",
       " 'Healthcare': 75,\n",
       " 'Data Science Courses': 72,\n",
       " 'TensorFlow': 71,\n",
       " 'Marketing': 70,\n",
       " 'Finance': 70,\n",
       " 'Clustering': 69,\n",
       " 'Regression': 67,\n",
       " 'Tableau': 67,\n",
       " 'Interview': 66,\n",
       " 'Ciencia De Dados': 66,\n",
       " 'Engineering': 63,\n",
       " 'Pytorch': 63,\n",
       " 'Udacity Nanodegree': 62,\n",
       " 'Politics': 60,\n",
       " 'Spark': 59,\n",
       " 'Blockchain': 57,\n",
       " 'Economics': 57,\n",
       " 'Tech': 56,\n",
       " 'Predictive Analytics': 55,\n",
       " 'Logistic Regression': 55,\n",
       " 'Cloud Computing': 55,\n",
       " 'Adventure': 55,\n",
       " 'Feature Engineering': 54,\n",
       " 'Beginner': 54,\n",
       " 'Research': 54,\n",
       " 'Data Cleaning': 53,\n",
       " 'Unsupervised Learning': 53,\n",
       " 'Women In Tech': 53,\n",
       " 'Leadership': 52,\n",
       " 'Software Engineering': 52,\n",
       " 'Intelligence Artificielle': 52,\n",
       " 'Time Series Analysis': 51,\n",
       " 'Probability': 51,\n",
       " 'Astronomy': 51,\n",
       " 'Numpy': 50,\n",
       " 'Career Advice': 50}"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top 100 tags \n",
    "counter = Counter(sort_orders)\n",
    "most_common = counter.most_common(100)\n",
    "most_common = [x[0] for x in most_common]\n",
    "\n",
    "most_common_dict = {}\n",
    "\n",
    "for tag in most_common:\n",
    "    most_common_dict[tag[0]] = tag[1]\n",
    "\n",
    "most_common_dict       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-488-f5e6d7b4d35d>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium_articles['is_top100'] = medium_articles['tag_list'].apply(specific_tags)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>article_url</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>date</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>is_top100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Top 10 Technology Trends for 2020</td>\n",
       "      <td>https://towardsdatascience.com/top-10-technolo...</td>\n",
       "      <td>3000</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Technology', 'Trends', 'Artificial Intellige...</td>\n",
       "      <td>[Technology, Artificial Intelligence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Top 10 Skills for a Data Scientist</td>\n",
       "      <td>https://towardsdatascience.com/top-10-skills-f...</td>\n",
       "      <td>2200</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Data Science', 'Technology', 'Business', 'Ma...</td>\n",
       "      <td>[Technology, Business, Machine Learning, Data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ML Ops: Machine Learning as an Engineering Dis...</td>\n",
       "      <td>https://towardsdatascience.com/ml-ops-machine-...</td>\n",
       "      <td>1300</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Data Science', 'Machine Learning', 'Data Eng...</td>\n",
       "      <td>[Machine Learning, Data Engineering, Towards D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Organizing your Python Code</td>\n",
       "      <td>https://medium.com/@k3no/organizing-your-pytho...</td>\n",
       "      <td>1200</td>\n",
       "      <td>13</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Python', 'Programming', 'Data Science', 'Cod...</td>\n",
       "      <td>[Python, Programming, Coding, Software Develop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How to be fancy with OOP in Python</td>\n",
       "      <td>https://towardsdatascience.com/how-to-be-fancy...</td>\n",
       "      <td>928</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Programming', 'Python', 'Data Science', 'Cod...</td>\n",
       "      <td>[Programming, Python, Coding]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              title  \\\n",
       "0      0                  Top 10 Technology Trends for 2020   \n",
       "1      1                 Top 10 Skills for a Data Scientist   \n",
       "2      2  ML Ops: Machine Learning as an Engineering Dis...   \n",
       "3      3                        Organizing your Python Code   \n",
       "4      4                 How to be fancy with OOP in Python   \n",
       "\n",
       "                                         article_url  claps  reading_time  \\\n",
       "0  https://towardsdatascience.com/top-10-technolo...   3000            10   \n",
       "1  https://towardsdatascience.com/top-10-skills-f...   2200             9   \n",
       "2  https://towardsdatascience.com/ml-ops-machine-...   1300            10   \n",
       "3  https://medium.com/@k3no/organizing-your-pytho...   1200            13   \n",
       "4  https://towardsdatascience.com/how-to-be-fancy...    928             3   \n",
       "\n",
       "         date                                           tag_list  \\\n",
       "0  2020-01-03  ['Technology', 'Trends', 'Artificial Intellige...   \n",
       "1  2020-01-03  ['Data Science', 'Technology', 'Business', 'Ma...   \n",
       "2  2020-01-03  ['Data Science', 'Machine Learning', 'Data Eng...   \n",
       "3  2020-01-03  ['Python', 'Programming', 'Data Science', 'Cod...   \n",
       "4  2020-01-03  ['Programming', 'Python', 'Data Science', 'Cod...   \n",
       "\n",
       "                                           is_top100  \n",
       "0              [Technology, Artificial Intelligence]  \n",
       "1     [Technology, Business, Machine Learning, Data]  \n",
       "2  [Machine Learning, Data Engineering, Towards D...  \n",
       "3  [Python, Programming, Coding, Software Develop...  \n",
       "4                      [Programming, Python, Coding]  "
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if top 100 tags in article\n",
    "\n",
    "def top_100(lst):\n",
    "    \"\"\"Checks if the top 100 tags mentioned are mentioned in an article\"\"\"\n",
    "    lst = ast.literal_eval(lst)\n",
    "    for i in lst:\n",
    "        if i in most_common_dict.keys():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "medium_articles['is_top100'] = medium_articles['tag_list'].apply(top_100)  \n",
    "medium_articles = medium_articles.loc[medium_articles.is_top100]\n",
    "copy_info = medium_articles.copy()\n",
    "\n",
    "\n",
    "# replaces True with the tags that are in the top 100\n",
    "\n",
    "def specific_tags(lst):\n",
    "    lst = ast.literal_eval(lst)\n",
    "    tags = []\n",
    "    for i in lst:\n",
    "        if i in most_common_dict.keys():\n",
    "            tags.append(i)\n",
    "    return tags\n",
    "        \n",
    "medium_articles['is_top100'] = medium_articles['tag_list'].apply(specific_tags)\n",
    "medium_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>mentions</th>\n",
       "      <th>avg_claps</th>\n",
       "      <th>avg_readtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>4040</td>\n",
       "      <td>71.564604</td>\n",
       "      <td>5.478713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "      <td>1748</td>\n",
       "      <td>63.665332</td>\n",
       "      <td>5.215675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>1714</td>\n",
       "      <td>103.471412</td>\n",
       "      <td>4.921820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>1184</td>\n",
       "      <td>37.119932</td>\n",
       "      <td>5.107264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data</td>\n",
       "      <td>1077</td>\n",
       "      <td>43.841226</td>\n",
       "      <td>4.558960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       tag  mentions   avg_claps  avg_readtime\n",
       "0         Machine Learning      4040   71.564604      5.478713\n",
       "1                   Python      1748   63.665332      5.215675\n",
       "2  Artificial Intelligence      1714  103.471412      4.921820\n",
       "3       Data Visualization      1184   37.119932      5.107264\n",
       "4                     Data      1077   43.841226      4.558960"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "final_df['tag'] = list(most_common_dict.keys())\n",
    "final_df['mentions'] = list(most_common_dict.values())\n",
    "\n",
    "final_claps = {}\n",
    "\n",
    "for i in most_common_dict.keys():\n",
    "    final_claps[i] = 0\n",
    "\n",
    "final_readtime = {}\n",
    "\n",
    "for i in most_common_dict.keys():\n",
    "    final_readtime[i] = 0\n",
    "    \n",
    "def claps(x):\n",
    "    for i in x[7]:\n",
    "        final_claps[i] += (x[3])\n",
    "\n",
    "def read_time(x):\n",
    "    for i in x[7]:\n",
    "        final_readtime[i] += (x[4])        \n",
    "    \n",
    "medium_articles.apply(claps, axis=1)\n",
    "medium_articles.apply(read_time, axis=1)\n",
    "\n",
    "final_df['avg_claps'] = list(final_claps.values())\n",
    "final_df['avg_readtime'] = list(final_readtime.values())\n",
    "final_df['avg_claps'] = final_df['avg_claps']/final_df['mentions']\n",
    "final_df['avg_readtime'] = final_df['avg_readtime']/final_df['mentions']\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('article_stats.csv', header=True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>article_url</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>date</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>is_top100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Top 10 Technology Trends for 2020</td>\n",
       "      <td>https://towardsdatascience.com/top-10-technolo...</td>\n",
       "      <td>3000</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Technology', 'Trends', 'Artificial Intellige...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Top 10 Skills for a Data Scientist</td>\n",
       "      <td>https://towardsdatascience.com/top-10-skills-f...</td>\n",
       "      <td>2200</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Data Science', 'Technology', 'Business', 'Ma...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ML Ops: Machine Learning as an Engineering Dis...</td>\n",
       "      <td>https://towardsdatascience.com/ml-ops-machine-...</td>\n",
       "      <td>1300</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Data Science', 'Machine Learning', 'Data Eng...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Organizing your Python Code</td>\n",
       "      <td>https://medium.com/@k3no/organizing-your-pytho...</td>\n",
       "      <td>1200</td>\n",
       "      <td>13</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Python', 'Programming', 'Data Science', 'Cod...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How to be fancy with OOP in Python</td>\n",
       "      <td>https://towardsdatascience.com/how-to-be-fancy...</td>\n",
       "      <td>928</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Programming', 'Python', 'Data Science', 'Cod...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              title  \\\n",
       "0      0                  Top 10 Technology Trends for 2020   \n",
       "1      1                 Top 10 Skills for a Data Scientist   \n",
       "2      2  ML Ops: Machine Learning as an Engineering Dis...   \n",
       "3      3                        Organizing your Python Code   \n",
       "4      4                 How to be fancy with OOP in Python   \n",
       "\n",
       "                                         article_url  claps  reading_time  \\\n",
       "0  https://towardsdatascience.com/top-10-technolo...   3000            10   \n",
       "1  https://towardsdatascience.com/top-10-skills-f...   2200             9   \n",
       "2  https://towardsdatascience.com/ml-ops-machine-...   1300            10   \n",
       "3  https://medium.com/@k3no/organizing-your-pytho...   1200            13   \n",
       "4  https://towardsdatascience.com/how-to-be-fancy...    928             3   \n",
       "\n",
       "         date                                           tag_list  is_top100  \n",
       "0  2020-01-03  ['Technology', 'Trends', 'Artificial Intellige...       True  \n",
       "1  2020-01-03  ['Data Science', 'Technology', 'Business', 'Ma...       True  \n",
       "2  2020-01-03  ['Data Science', 'Machine Learning', 'Data Eng...       True  \n",
       "3  2020-01-03  ['Python', 'Programming', 'Data Science', 'Cod...       True  \n",
       "4  2020-01-03  ['Programming', 'Python', 'Data Science', 'Cod...       True  "
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grabs the articles that contain top 100 tags\n",
    "copy_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>article_url</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>date</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>is_top100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>technology</td>\n",
       "      <td>https://towardsdatascience.com/top-10-technolo...</td>\n",
       "      <td>3000</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Technology', 'Trends', 'Artificial Intellige...</td>\n",
       "      <td>[Technology, Artificial Intelligence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>https://towardsdatascience.com/top-10-skills-f...</td>\n",
       "      <td>2200</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Data Science', 'Technology', 'Business', 'Ma...</td>\n",
       "      <td>[Technology, Business, Machine Learning, Data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>machine learning engineering discipline</td>\n",
       "      <td>https://towardsdatascience.com/ml-ops-machine-...</td>\n",
       "      <td>1300</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Data Science', 'Machine Learning', 'Data Eng...</td>\n",
       "      <td>[Machine Learning, Data Engineering, Towards D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>python code</td>\n",
       "      <td>https://medium.com/@k3no/organizing-your-pytho...</td>\n",
       "      <td>1200</td>\n",
       "      <td>13</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Python', 'Programming', 'Data Science', 'Cod...</td>\n",
       "      <td>[Python, Programming, Coding, Software Develop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fancy python</td>\n",
       "      <td>https://towardsdatascience.com/how-to-be-fancy...</td>\n",
       "      <td>928</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>['Programming', 'Python', 'Data Science', 'Cod...</td>\n",
       "      <td>[Programming, Python, Coding]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                    title  \\\n",
       "0      0                               technology   \n",
       "1      1                           data scientist   \n",
       "2      2  machine learning engineering discipline   \n",
       "3      3                              python code   \n",
       "4      4                             fancy python   \n",
       "\n",
       "                                         article_url  claps  reading_time  \\\n",
       "0  https://towardsdatascience.com/top-10-technolo...   3000            10   \n",
       "1  https://towardsdatascience.com/top-10-skills-f...   2200             9   \n",
       "2  https://towardsdatascience.com/ml-ops-machine-...   1300            10   \n",
       "3  https://medium.com/@k3no/organizing-your-pytho...   1200            13   \n",
       "4  https://towardsdatascience.com/how-to-be-fancy...    928             3   \n",
       "\n",
       "         date                                           tag_list  \\\n",
       "0  2020-01-03  ['Technology', 'Trends', 'Artificial Intellige...   \n",
       "1  2020-01-03  ['Data Science', 'Technology', 'Business', 'Ma...   \n",
       "2  2020-01-03  ['Data Science', 'Machine Learning', 'Data Eng...   \n",
       "3  2020-01-03  ['Python', 'Programming', 'Data Science', 'Cod...   \n",
       "4  2020-01-03  ['Programming', 'Python', 'Data Science', 'Cod...   \n",
       "\n",
       "                                           is_top100  \n",
       "0              [Technology, Artificial Intelligence]  \n",
       "1     [Technology, Business, Machine Learning, Data]  \n",
       "2  [Machine Learning, Data Engineering, Towards D...  \n",
       "3  [Python, Programming, Coding, Software Develop...  \n",
       "4                      [Programming, Python, Coding]  "
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of english stop words\n",
    "stop = stopwords.words('english')\n",
    "copy_info['title'] = copy_info['title'].str.lower().str.split()\n",
    "copy_info['title'] = copy_info['title'].apply(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "# get rid of punctuation\n",
    "def remove_punc(lst):\n",
    "    return list(filter(lambda x:x, map(lambda x:re.sub(r'[^A-Za-z]', '', x), lst)))\n",
    "copy_info['title'] = copy_info['title'].apply(remove_punc)\n",
    "\n",
    "# combine the list of strings again\n",
    "def combine(lst):\n",
    "    return \" \".join(lst)\n",
    "copy_info['title'] = copy_info['title'].apply(combine)\n",
    "\n",
    "words = set(nltk.corpus.words.words())\n",
    "# remove non-english words\n",
    "def remove_non_english(string):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(string) if w.lower() in words or not w.isalpha())\n",
    "copy_info['title'] = copy_info['title'].apply(remove_non_english)\n",
    "\n",
    "# remove words that are less than or equal to 2 letters\n",
    "def remove_two_letter(string):\n",
    "    shortword = re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
    "    return shortword.sub('', string)\n",
    "copy_info['title'] = copy_info['title'].apply(remove_two_letter)\n",
    "\n",
    "def manual_removal(string):\n",
    "    \"\"\"Removed strings affiliated with spam articles\"\"\"\n",
    "    shortword = re.compile(r'baba|amil|kala|bibi|black|magic')\n",
    "    return shortword.sub('', string)\n",
    "copy_info['title'] = copy_info['title'].apply(manual_removal)\n",
    "\n",
    "copy_info['is_top100'] = medium_articles['is_top100']\n",
    "\n",
    "copy_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', 2966),\n",
       " ('science', 1198),\n",
       " ('learning', 1007),\n",
       " ('machine', 785),\n",
       " ('python', 723),\n",
       " ('strong', 706),\n",
       " ('covid', 566),\n",
       " ('analysis', 403),\n",
       " ('part', 392),\n",
       " ('analytics', 246),\n",
       " ('model', 206),\n",
       " ('scientist', 202),\n",
       " ('regression', 174),\n",
       " ('specialist', 160),\n",
       " ('deep', 156),\n",
       " ('introduction', 154),\n",
       " ('best', 147),\n",
       " ('guide', 137),\n",
       " ('world', 136),\n",
       " ('intelligence', 136),\n",
       " ('neural', 127),\n",
       " ('artificial', 124),\n",
       " ('classification', 119),\n",
       " ('linear', 118),\n",
       " ('business', 117),\n",
       " ('visualization', 114),\n",
       " ('project', 112),\n",
       " ('learn', 111),\n",
       " ('know', 103),\n",
       " ('real', 103),\n",
       " ('understanding', 100),\n",
       " ('expert', 96),\n",
       " ('prediction', 95),\n",
       " ('time', 90),\n",
       " ('need', 90),\n",
       " ('building', 88),\n",
       " ('detection', 83),\n",
       " ('language', 82),\n",
       " ('series', 81),\n",
       " ('first', 80),\n",
       " ('customer', 75),\n",
       " ('canada', 75),\n",
       " ('famous', 75),\n",
       " ('career', 74),\n",
       " ('feature', 73),\n",
       " ('image', 73),\n",
       " ('engineering', 72),\n",
       " ('clustering', 71),\n",
       " ('algorithm', 71),\n",
       " ('network', 70),\n",
       " ('statistics', 70),\n",
       " ('exploratory', 69),\n",
       " ('scraping', 68),\n",
       " ('simple', 68),\n",
       " ('para', 67),\n",
       " ('make', 66),\n",
       " ('code', 65),\n",
       " ('journey', 65),\n",
       " ('york', 65),\n",
       " ('build', 64),\n",
       " ('getting', 64),\n",
       " ('future', 64),\n",
       " ('market', 62),\n",
       " ('love', 61),\n",
       " ('cloud', 60),\n",
       " ('training', 59),\n",
       " ('case', 58),\n",
       " ('industry', 55),\n",
       " ('help', 55),\n",
       " ('interview', 55),\n",
       " ('course', 55),\n",
       " ('news', 54),\n",
       " ('basic', 54),\n",
       " ('astrologer', 53),\n",
       " ('predict', 52),\n",
       " ('week', 51),\n",
       " ('logistic', 51),\n",
       " ('create', 51),\n",
       " ('study', 51),\n",
       " ('system', 50),\n",
       " ('easy', 49),\n",
       " ('price', 49),\n",
       " ('exploring', 49),\n",
       " ('important', 48),\n",
       " ('modeling', 48),\n",
       " ('free', 48),\n",
       " ('approach', 47),\n",
       " ('pandemic', 47),\n",
       " ('become', 45),\n",
       " ('better', 45),\n",
       " ('testing', 44),\n",
       " ('power', 44),\n",
       " ('problem', 44),\n",
       " ('work', 44),\n",
       " ('ways', 44),\n",
       " ('research', 44),\n",
       " ('spark', 44),\n",
       " ('impact', 43),\n",
       " ('start', 43),\n",
       " ('notebook', 43),\n",
       " ('text', 42),\n",
       " ('segmentation', 42),\n",
       " ('open', 42),\n",
       " ('analyst', 42),\n",
       " ('decision', 41),\n",
       " ('story', 41),\n",
       " ('team', 41),\n",
       " ('span', 41),\n",
       " ('marketing', 41),\n",
       " ('natural', 40),\n",
       " ('mining', 40),\n",
       " ('step', 40),\n",
       " ('review', 40),\n",
       " ('virtual', 40),\n",
       " ('forecasting', 39),\n",
       " ('metrics', 38),\n",
       " ('performance', 38),\n",
       " ('boston', 37),\n",
       " ('scratch', 37),\n",
       " ('twitter', 37),\n",
       " ('look', 37),\n",
       " ('social', 37),\n",
       " ('search', 36),\n",
       " ('capstone', 36),\n",
       " ('based', 36),\n",
       " ('classifier', 36),\n",
       " ('technology', 35),\n",
       " ('used', 35),\n",
       " ('random', 35),\n",
       " ('strategy', 34),\n",
       " ('platform', 34),\n",
       " ('sentiment', 34),\n",
       " ('dont', 34),\n",
       " ('churn', 33),\n",
       " ('process', 33),\n",
       " ('design', 33),\n",
       " ('tableau', 33),\n",
       " ('graph', 33),\n",
       " ('recognition', 32),\n",
       " ('bias', 32),\n",
       " ('object', 32),\n",
       " ('life', 32),\n",
       " ('good', 32),\n",
       " ('value', 32),\n",
       " ('challenge', 32),\n",
       " ('function', 32),\n",
       " ('making', 32),\n",
       " ('predictive', 32),\n",
       " ('experience', 32),\n",
       " ('role', 32),\n",
       " ('marriage', 32),\n",
       " ('statistical', 31),\n",
       " ('next', 31),\n",
       " ('dashboard', 31),\n",
       " ('without', 31),\n",
       " ('program', 31),\n",
       " ('behind', 31),\n",
       " ('tech', 31),\n",
       " ('different', 31),\n",
       " ('really', 31),\n",
       " ('development', 31),\n",
       " ('computer', 31),\n",
       " ('whats', 31),\n",
       " ('application', 31),\n",
       " ('pipeline', 31),\n",
       " ('face', 30),\n",
       " ('house', 30),\n",
       " ('want', 30),\n",
       " ('like', 30),\n",
       " ('corona', 30),\n",
       " ('tutorial', 29),\n",
       " ('brief', 29),\n",
       " ('financial', 29),\n",
       " ('weekly', 28),\n",
       " ('finding', 28),\n",
       " ('people', 28),\n",
       " ('library', 28),\n",
       " ('gradient', 28),\n",
       " ('zero', 27),\n",
       " ('dive', 27),\n",
       " ('hypothesis', 27),\n",
       " ('company', 27),\n",
       " ('veri', 27),\n",
       " ('digital', 27),\n",
       " ('find', 27),\n",
       " ('apache', 27),\n",
       " ('right', 27),\n",
       " ('recommender', 26),\n",
       " ('probability', 26),\n",
       " ('management', 26),\n",
       " ('path', 26),\n",
       " ('product', 26),\n",
       " ('practical', 26),\n",
       " ('back', 26),\n",
       " ('growth', 26),\n",
       " ('global', 26),\n",
       " ('paper', 26),\n",
       " ('beyond', 26),\n",
       " ('vector', 25),\n",
       " ('information', 25),\n",
       " ('choose', 25),\n",
       " ('health', 25),\n",
       " ('perspective', 25),\n",
       " ('risk', 25),\n",
       " ('engineer', 25),\n",
       " ('solution', 24),\n",
       " ('support', 24),\n",
       " ('complete', 24),\n",
       " ('overview', 24),\n",
       " ('every', 24),\n",
       " ('update', 24),\n",
       " ('quality', 24),\n",
       " ('rate', 24),\n",
       " ('improve', 24),\n",
       " ('importance', 24),\n",
       " ('removal', 24),\n",
       " ('production', 24),\n",
       " ('deploy', 24),\n",
       " ('crisis', 24),\n",
       " ('contact', 24),\n",
       " ('implementation', 23),\n",
       " ('handling', 23),\n",
       " ('forest', 23),\n",
       " ('stock', 23),\n",
       " ('common', 23),\n",
       " ('book', 23),\n",
       " ('popular', 23),\n",
       " ('developer', 23),\n",
       " ('turkey', 23),\n",
       " ('spell', 23),\n",
       " ('read', 22),\n",
       " ('disease', 22),\n",
       " ('offer', 22),\n",
       " ('advanced', 22),\n",
       " ('excel', 22),\n",
       " ('understand', 22),\n",
       " ('music', 22),\n",
       " ('today', 22),\n",
       " ('everything', 22),\n",
       " ('tool', 22),\n",
       " ('difference', 22),\n",
       " ('virus', 22),\n",
       " ('word', 22),\n",
       " ('recommendation', 22),\n",
       " ('mathematics', 22),\n",
       " ('azure', 22),\n",
       " ('matrix', 21),\n",
       " ('engine', 21),\n",
       " ('unsupervised', 21),\n",
       " ('tree', 21),\n",
       " ('test', 21),\n",
       " ('missing', 21),\n",
       " ('studio', 21),\n",
       " ('success', 21),\n",
       " ('reinforcement', 21),\n",
       " ('vision', 21),\n",
       " ('city', 21),\n",
       " ('much', 21),\n",
       " ('exploration', 21),\n",
       " ('quick', 21),\n",
       " ('three', 21),\n",
       " ('optimization', 20),\n",
       " ('naive', 20),\n",
       " ('level', 20),\n",
       " ('cleaning', 20),\n",
       " ('made', 20),\n",
       " ('demand', 20),\n",
       " ('media', 20),\n",
       " ('must', 20),\n",
       " ('privacy', 20),\n",
       " ('small', 20),\n",
       " ('effective', 20),\n",
       " ('easily', 20),\n",
       " ('times', 20),\n",
       " ('correlation', 19),\n",
       " ('visual', 19),\n",
       " ('interactive', 19),\n",
       " ('selection', 19),\n",
       " ('scale', 19),\n",
       " ('learned', 19),\n",
       " ('environment', 19),\n",
       " ('mean', 19),\n",
       " ('categorical', 19),\n",
       " ('spread', 19),\n",
       " ('architecture', 19),\n",
       " ('descent', 19),\n",
       " ('change', 19),\n",
       " ('battle', 19),\n",
       " ('outbreak', 19),\n",
       " ('driven', 18),\n",
       " ('chart', 18),\n",
       " ('towards', 18),\n",
       " ('docker', 18),\n",
       " ('smart', 18),\n",
       " ('survey', 18),\n",
       " ('curve', 18),\n",
       " ('great', 18),\n",
       " ('working', 18),\n",
       " ('human', 18),\n",
       " ('conference', 18)]"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grabs top 100 siginificant words in the titles of articles that contain top 100 tags\n",
    "top_100_titles = Counter(\" \".join(copy_info[\"title\"]).split()).most_common(100)\n",
    "top_100_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>2966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>science</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>learning</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>machine</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  occurrence\n",
       "0      data        2966\n",
       "1   science        1198\n",
       "2  learning        1007\n",
       "3   machine         785\n",
       "4    python         723"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the list above into a dataframe to enter into Tableau\n",
    "top_100_titles_df_main = pd.DataFrame(top_100_titles, columns = ['word', 'occurrence'])\n",
    "top_100_titles_df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-494-dbbf481a96fc>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium_articles['is_top_tag'] = medium_articles.apply(lambda x: top_tag(x['tag_list'], tag), axis=1)\n",
      "<ipython-input-494-dbbf481a96fc>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium_articles_copy['title'] = medium_articles_copy['title'].str.lower().str.split()\n",
      "<ipython-input-494-dbbf481a96fc>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium_articles_copy['title'] = medium_articles_copy['title'].apply(lambda x: [item for item in x if item not in stop])\n",
      "<ipython-input-494-dbbf481a96fc>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium_articles_copy['title'] = medium_articles_copy['title'].apply(remove_punc)\n",
      "<ipython-input-494-dbbf481a96fc>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium_articles_copy['title'] = medium_articles_copy['title'].apply(combine)\n",
      "<ipython-input-494-dbbf481a96fc>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium_articles_copy['title'] = medium_articles_copy['title'].apply(remove_non_english)\n",
      "<ipython-input-494-dbbf481a96fc>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium_articles_copy['title'] = medium_articles_copy['title'].apply(remove_two_letter)\n",
      "<ipython-input-494-dbbf481a96fc>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  medium_articles_copy['title'] = medium_articles_copy['title'].apply(manual_removal)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurrence</th>\n",
       "      <th>tag</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>957</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>23.688119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning</td>\n",
       "      <td>861</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>21.311881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine</td>\n",
       "      <td>732</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>18.118812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>science</td>\n",
       "      <td>471</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>11.658416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strong</td>\n",
       "      <td>250</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>6.188119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>Career Advice</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>soft</td>\n",
       "      <td>1</td>\n",
       "      <td>Career Advice</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>skill</td>\n",
       "      <td>1</td>\n",
       "      <td>Career Advice</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>without</td>\n",
       "      <td>1</td>\n",
       "      <td>Career Advice</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>degree</td>\n",
       "      <td>1</td>\n",
       "      <td>Career Advice</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  occurrence               tag       rate\n",
       "0         data         957  Machine Learning  23.688119\n",
       "1     learning         861  Machine Learning  21.311881\n",
       "2      machine         732  Machine Learning  18.118812\n",
       "3      science         471  Machine Learning  11.658416\n",
       "4       strong         250  Machine Learning   6.188119\n",
       "...        ...         ...               ...        ...\n",
       "1995      best           1     Career Advice   2.000000\n",
       "1996      soft           1     Career Advice   2.000000\n",
       "1997     skill           1     Career Advice   2.000000\n",
       "1998   without           1     Career Advice   2.000000\n",
       "1999    degree           1     Career Advice   2.000000\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "def top_tag(lst, tag):\n",
    "    \"\"\"Checks if the top 100 tags mentioned are mentioned in an article\"\"\"\n",
    "    lst = ast.literal_eval(lst)\n",
    "    for i in lst:\n",
    "        if i == tag:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for tag in list(most_common_dict.keys()):\n",
    "    medium_articles['is_top_tag'] = medium_articles.apply(lambda x: top_tag(x['tag_list'], tag), axis=1)  \n",
    "    medium_articles_copy = medium_articles.loc[medium_articles.is_top_tag]\n",
    "    \n",
    "    #clean the titles\n",
    "    medium_articles_copy['title'] = medium_articles_copy['title'].str.lower().str.split()\n",
    "    medium_articles_copy['title'] = medium_articles_copy['title'].apply(lambda x: [item for item in x if item not in stop])\n",
    "    \n",
    "    medium_articles_copy['title'] = medium_articles_copy['title'].apply(remove_punc)\n",
    "\n",
    "    medium_articles_copy['title'] = medium_articles_copy['title'].apply(combine)\n",
    "\n",
    "    medium_articles_copy['title'] = medium_articles_copy['title'].apply(remove_non_english)\n",
    "\n",
    "    medium_articles_copy['title'] = medium_articles_copy['title'].apply(remove_two_letter)\n",
    "\n",
    "    medium_articles_copy['title'] = medium_articles_copy['title'].apply(manual_removal)\n",
    "    \n",
    "    top_100_titles = Counter(\" \".join(medium_articles_copy[\"title\"]).split()).most_common(20)\n",
    "    \n",
    "    if count == 0:\n",
    "        top_100_titles_df = pd.DataFrame(top_100_titles, columns = ['word', 'occurrence'])\n",
    "        top_100_titles_df['tag'] = tag\n",
    "        top_100_titles_df['rate'] = top_100_titles_df['occurrence']/list(most_common_dict.values())[count]\n",
    "        top_100_titles_df['rate'] = top_100_titles_df['rate'] * 100\n",
    "    else:\n",
    "        top_100_titles_df_2 = pd.DataFrame(top_100_titles, columns = ['word', 'occurrence'])\n",
    "        top_100_titles_df_2['tag'] = tag\n",
    "        top_100_titles_df_2['rate'] = top_100_titles_df_2['occurrence']/list(most_common_dict.values())[count]\n",
    "        top_100_titles_df_2['rate'] = top_100_titles_df_2['rate'] * 100\n",
    "        top_100_titles_df = pd.concat([top_100_titles_df, top_100_titles_df_2], ignore_index=True, sort=False)\n",
    "    count+=1\n",
    "        \n",
    "top_100_titles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_100_titles_df.groupby('word', as_index=False).sum()[['word', 'occurrence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_titles_df.to_csv('top_title_words_w_tag_4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
